head     1.1;
branch   1.1.1;
access   ;
symbols  initial:1.1.1.1 initial:1.1.1;
locks    ; strict;
comment  @# @;


1.1
date     98.12.07.21.34.57;  author daw;  state Exp;
branches 1.1.1.1;
next     ;

1.1.1.1
date     98.12.07.21.34.57;  author daw;  state Exp;
branches ;
next     ;


desc
@@



1.1
log
@Initial revision
@
text
@structure Context = 
  struct
        (* FIX: Using `None' might be a bad idea.

	   If we generate a constraint ctx >= ctx', and then later
	   generate another constraint ctx' >= ctx'', we'd intuitively
	   like to think that the constraint ctx >= ctx'' will follow.
	   But this doesn't work when ctx' = None.

	   Maybe it would be better to use `top' instead of `None'?

	   This would necessitate creating a lattice that works for
	   both Int and Str contexts.  One approach might be to use
	   tuples: e.g. (t,(siz,len)), where t is a Int term
	   representing this expression's integer value when evaluated
	   in an integer context, and (siz,len) is a Str term
	   representing this expression's size and length when evaluated
	   in a string context.
	   Then we could replace Int(t) => (t,(Z,Z)),
	   Str({siz,len}) => (Z,(siz,len)), and None => (Z,(Z,Z)),
	   where Z denotes the set of all integers,
           so that top = (Z,(Z,Z)).

	   In any case, it's not clear that the data structure below
	   is exactly right; but I guess it will do for now.
	*)
        datatype Context = Int of Constraint.term
          | Str of {siz:Constraint.term,len:Constraint.term}
          | StringTerminator | None;


	fun toString (Int t) = "Int<" ^ (Constraint.toString t) ^ ">"
	 | toString (Str {siz,len}) = "Str(siz=<" ^ (Constraint.toString siz)
	     ^ ">, len=<" ^ (Constraint.toString len) ^ ">)"
	 | toString StringTerminator = "StrTerm"
	 | toString None = "None"
  end
@


1.1.1.1
log
@
@
text
@@
