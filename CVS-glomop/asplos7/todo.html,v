head	1.2;
access;
symbols;
locks; strict;
comment	@# @;


1.2
date	96.10.12.02.58.32;	author fox;	state Exp;
branches;
next	1.1;

1.1
date	96.06.26.02.57.52;	author fox;	state Exp;
branches;
next	;


desc
@@


1.2
log
@*** empty log message ***
@
text
@<html><title>ASPLOS to do</title></head><body>

Things with ** are thought to be central to paper and must be presented
as such.

Things with ++ were said by more than one reviewer.

<h1>Principles</h1>
<ul>
  <li> what's the best way to address client variation (how to do
       adaptation) 
       <ul>
         <li> assign higher semantic content to different
              parts of information, since this gives a way to quantify
              what can be downgraded/thorwn away.
         <li> best way to assign higher semantic content: have typed
              data.  operations 
              over the typed data implement the mechanisms for adaptation.
         <li> to have typed data, need to have application deal with
              data at higher than transport level.
         <li> Ergo, want an architecture that allows you to specify high
              level types and 
              operations on them (distillation, refinement) as a way of
              specifying how 
              to do adaptation.
       </ul>
  <li> Why to do on-demand
       <ul>
         <li> gives you fine granularity across all variation
         <li> because you can! (non-obvious observation we made
              <i>after</i> prototype was implemented)
       </ul>
  <li> Doing it at server vs. in proxy
       <ul>
         <li> "Odyssey" model covers few documents, few points in variation
              space (granularity), and imposes server costs
              (administration and compute cycles).  
         <li> proxy allows separation of concerns.  Server concentrates
              on serving high quality content; proxy worries about
              adaptation.  Manage the network at the application level
              (as previously people have managed memory at the
              application level, using a similar chain of reasoning).
         <li> But the principle of
              on-demand distillation will still hold. 
              (trade cycles for bandwidth)
         <li> "how many cycles is a Mbit worth?"
       </ul>
  <li> refinement: allows you to "change your mind" about something that
       was aggressively distilled.
  <li> NCM: part of the architecture; separate detection of bandwidth changes
       from ability to adapt to change. Our architecture provides the 
       latter for
       free.  How to detect the former is the subject of a work in progress.
  <li> the <i>ability</i> to
       push compelxity away from client, into NW infrastructure.
       important for weak clients.
       <ul>
         <li> no changes to legacy servers
         <li> servers don't pay adaptation costs
       </ul>
  <li> controlling both endpoints of the painful part of
       mobility - the single long lived conn. from the client to the
       well-connected world
</ul>

<h1>BIG THINGS from reviewers</h1>

<b>Distillation parameters</b>
<ul>
  <li> Specifying axes
  <li> Presenting to users- image browser?
  <li> Solving opt. problem: constraint values to distill parms - neural net?
  <li> explain use of automated stat. modeling
  <li> at least mention how done for GIF, and point out that it would be
       useful to encode &quot;effective bpp&quot; in original img
       format! do other fmts do this?
</ul>
      

<b>What's new and different (and likely to admit solution based
on our experience so far)</b>
<ol>
  <li> Adaptation is on the fly (as opposed to serving multiple
       representations) 
  <li> This enables adaptation to be dynamic and fine-grained (as
       opposed to picking a static profile)
  <li> Lossy, semantic compression (vs. generic lossless compression)
</ol>

<b>Some points about methodology</b>
<ul>
  <li> research agenda: &quot;here are some intersesting research issues, and a
       system we're building in order to investigate them&quot;
  <li> iterating on design/build/design because some parts of system must
       be built &amp; observed in order to really do research on them.
</ul>

<b>Issues:</b>
<ul>
  <li> scalability
  <li> wide range of clients
       
  <li> dynamic adaptation (NCM): there is no paper!
       <ul>
         <li>  check out what is implemented, see if it even works
         <li>  describe concretely how NCM works>?
         <li>  need to make explicit that this is central to the work
       </ul>
</ul>

<h1>SMALL THINGS in order of importance, approximately</h1>

<ul>
  <li> (AF) text distillation: need stronger conclusions (minimum), or
       more examples (as for images)<br>
       - reviewer: &quot;It would be *most* interesting to see when
       distillation pays and when it doesn't for each datatype.&quot;

  <li> (EA) video: evidently, need clearer explan. of DCT intermediate
       form, and 
  more results/examples.   

  <li> (AF) some measure of performance as perceived by end user
  - demonstrate upper bound on seeing a page w/thumbnails when using proxy?
  - how to improve the end-to-end latency graphs that are in there now

  <li> (AF) relnship to C/S e2e strategies
  - admin @@ server, wide range o'clients<br>
  - can compose w/e2e strategy eg odyssey<br>
       - if serving many clients, single server can't scale to provide
       &quot;all&quot;   representations clients want

  <li> (AF) clarify intermediate format vs. NxN for text, images.
       - separate transcoding architecture from protocol architecture; show
       that we don't need to add &quot;transcoders&quot; every time there is a new
       protocol, just need &quot;document parsers&quot; and &quot;document
       fetchers&quot; for the 
       new protocol.


  <li> (SG) reviewer: &quot;This [investigating extent to which different transcoding
       techniques will prove to be acceptable to clients] is a perceptual
       issue, and so it seems to me can be answered only through
       experimentation.  To perform these experiments, one needs a system such
       as this; in that sense, the system could serve as a vehicle to answering
       this important question.  However, the work contained here is simply a
       description of the system (as well as some discussion of design
       choices).&quot;  user's perception of &quot;quality&quot;: nontrivial to predict, other
       work exists [cite], this system will undoubtedly be affected by it, but it's
       not central to *our* research.

  <li> (SG) better description of simluations

  <li> abstract: When I read &quot;reduce the impact of . . . variation
among network clients&quot; I thought you were somehow going to cause
them to have the same functionality, which isn't the point at all.

  <li> (SG) delivery classes: as we did at retreat; describe as an optimization.

  <li> (AF) need an &quot;implementation&quot; section:<br>
       - GloMop apps: gmproxyd, gmwish, image browser<br>
       - unmodified apps<br>
       - image browser<br>

  <li> (SG) security: charon pointer
</ul>

<b>RELATED WORK</b>

<ul>
<li> <a
     href="http://www.aubg.edu:8080/cii/src/delegate3.0.17/doc/Manual.txt">http://www.aubg.edu:8080/cii/src/delegate3.0.17/doc/Manual.txt</a> (Japanese character conversion proxy)
     
<li> - Cite Mowgli
<li> - point out that caching is (and should be) orthogonal
      to our system (eg Harvest)
<li> - Cite Bruce Zenel's stuff at Columbia.  For my summary of it (and
   what's different), <a
     href="http://www.cs.berkeley.edu/~fox/summaries/glomop/zenel.html">click here</a> 
</ul>

<b>ACKS</b>

<ul>
  <li> -DARPA/GloMo grant
  <li> -NSERC (steve)
  <li> -UCB fshp (armando)
  <li> elan??
  <li> companies??
</ul>


@


1.1
log
@added html "to do" items
@
text
@d8 59
a66 1
BIG THINGS
d75 2
a76 2
       useful to encode &quot;effective bpp&quot; in original img format! do other fmts
       do this?
d90 1
d111 1
a111 1
SMALL THINGS in order of importance, approximately
d171 3
d185 1
a185 1
  <li> -DARPA grant
d188 2
a189 1
  <li> -companies?      
@
