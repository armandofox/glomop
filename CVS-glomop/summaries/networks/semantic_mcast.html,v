head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	98.05.03.20.18.29;	author fox;	state Exp;
branches;
next	;


desc
@@


1.1
log
@*** empty log message ***
@
text
@<html>
<title>
Semantic Multicast
</title>
<body>
<a href="index.html"><i>Back to index</i></a>
<h1>
Semantic
Multicast: Intelligently Sharing Collaborative Sessions
</h1>
<strong>
Son Dao, Lixia Zhang, et al.
</strong>

<p><b>One-line summary:</b>

</p>

<h2>Overview/Main Points</h2>

<ul>
  <li> Build channel-to-channel aggregation proxies, and allow
       subscription on the outputs based on user profiles.
       <I>Sure, I knew that, but the hard part is how
       to extract metadata describing the channel content.  THis paper
       assumes the metadata infrastructure and standard formats are
       already in place, as in: "Various fields are associated with
       weighted similarity ontologies."</i>
  <li> Basic construct: <i>semantic multicast graph</i>, where each node
       represents a "range and quality" of semantic topics present in
       the set of collaborative streams and user profiles.  We add a
       node dynamically if a "large set" of user profiles is likely to
       be interested in it, and if the node would have access to input streams
       close to the topic of interest.
  <li> To compute this, intersect user profiles by comparing
              nodes in the two profiles that have a "common parent" in
              the <i>similarity ontology</i> that describes the topic
              space, and let the intersection be the common parent
              weighted by an error factor proportional to the weights
              between the topics and their parent in the ontology.
              <i>The basic idea is that given some similarity weightings
              between a subtopic and its parents, you can estimate how
              similar two subtopics are to each other.</i>
  <li> Geographic criteria: try to instantiate nodes "close to" clusters
       of users that would use them, to avoid a lot of overlapping
       network traffic.
  <li> Each aggregation proxy announces itself and independently
       computes semantic multicast graph optimized for its user
       population and the stream data of other proxies it can see.
  <li> Similarly, each user announced himself to any proxy, and his
       profile automatically gets forwarded to other appropriate proxies
       that this one knows about.
</ul>

<h2>Relevance</h2>

<ul>
  <li> Nice generalization of multicast with semantics subscription
       groups.
  <li> Nice application of multicast announcement and distributed soft
       state (seems like each user can store his profile locally and
       just announce it to any proxy at signup time) to "groups of
       cooperating proxies" problem.  But the paper doesn't seem to
       exploit this, arguing instead for statefulness in proxies
       remembering disconnection state of their users.
</ul>

<h2>Flaws</h2>

<ul>
  <li> Metadata infrastructure and "similarity ontologies" are the hard
       part.  Standards and deployment aside, everyone else who's tried
       to construct a static universal namespace for just abuot anything
       has foundered.  Would be nice if there were a way for namespaces
       to describe themselves, as an extension of the ontology stuff;
       then perhaps some minimal user-interaction with particular stream
       servers could be used as the basis of how to derive the ontology
       info for a particular set of sources.
  <li> Each proxy is supposed to remember connected/disconnected state
       of each of its users, so when  a disconnected user reconnects,
       proxy can "fast forward" thru session or allow user to catchup on
       missed stuff.  How this is accomplished is not clearly spelled out.
  <li> Implementation as described is stateful, but could be statless or
       SRM! (See "relevance" above)
<hr>
<a href="index.html"><i>Back to index</i></a>

</body></html>
@
