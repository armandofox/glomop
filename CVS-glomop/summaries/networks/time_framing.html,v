head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	97.04.21.15.41.21;	author fox;	state Exp;
branches;
next	;


desc
@@


1.1
log
@*** empty log message ***
@
text
@<html>
<title>
Time Framing
</title>
<body>
<a href="index.html"><i>Back to index</i></a>
<h1>
A Framing Strategy for Congestion Management
</h1>
<strong>
S.J. Golestani, Bellcore
</strong>

<p><b>One-line summary:</b> Admission based congestion control on
multiple streams with varying real-time constraints.  Group
packets with similar delay requirements into "time frames", multiplex
the frames onto each link, and at each switch/router, minimize
the "phase difference" (delay between extracting packet from arriving
frame and placing it in next departing frame of the same class).  </p>

<h2>Overview/Main Points</h2>

<ul>
  <li> Idea: exploit loss tolerance of different classes of RT traffic,
       "striking balance between statistical mux'ing gain and packet
       loss probability"
  <li> Connection parameters:
       <ul>
         <li> "Frame size" Tg (division of time axis); we call it a
              "type g frame".  Larger Tg implies shorter frame. Various
              Ti's correspond to different
              families of services, and need not be multiples of each
              other or anything like that.
         <li> Steady state transmission rate Rk
         <li> (r,Tg) smoothness with respect to link L: aggregated
              length of pkts received  during each arriving frame of
              type g over L is no more than r&nbsp;x&nbsp;Tg bits.  (For
              fixed size pkts of size S, says number of received packets
              is at most r&nbsp;x&nbsp;Tg&nbsp;x&nbsp;1/S.)  Note that
              this property is dependent on choice of time origin, but
              that turns out not to matter.
         <li> <b>Admission rule:</b> any packet that violates (r,Tg)
              smoothness of the connection is not admitted
              (i.e. dropped).
         <li> So, we use this rule to guarantee dropping of packets that
              would cause bursts to build up.
       </ul>
  <li> Stop-and-go queueing: goal is to preserve the smoothness property
       (above) which we currently guarantee <i>only on entry</i> to the
       network.
       <ul>
         <li> Phase mismatch at a switch: delay between the end of the
              arrival of a type g
              frame, and the beginning of the departure of the
              next type g frame on the outgoing link for this
              connection.  (By definition, always less than Tg.)
         <li> The <i>eligible set</i> of packets to go out on next
              outgoing type g frame is at most those packets that
              arrived on the last type g frame.  Packets from the next
              incoming type g frame won't be eligible until the whole
              frame arrives.
         <li> An eligible type g' packet has priority over an eligible
              type g packet frame if g'&gt;g.  (I.e. packets in shorter
              frames have
              non-preemptive priority over packets in longer frames)
         <li> Loop: Select and transmit eligible packets until none left.
       </ul>
       
  <li> Some properties of this algorithm:
       <ul>
         <li> Stop-and-go queueing prevents packet clustering.
         <li> To avoid packet loss for type g, allocate a buffer of size
              Tg&nbsp;x&nbsp;C(g,l)&nbsp;x&nbsp;B, where B&lt;3 is a
              bounding constant (proof in appendix) and C(g,l) is the
              aggregate capacity 
              allocated to all connections of type g traversing link l
              into the switch.
         <li> Due to minimizing the phase delay, end-to-end delay of a
              given packet is deterministic, modulo its position in the
              arriving/outgoing frame (which is also bounded).  The
              amount of variation is dependent on the frame size, so put
              more delay-tolerant traffic in larger frames.
       </ul>
  <li> Tradeoffs:
       <ul>
         <li> Choice of frame size: trade off end-to-end delay 
              vs. granularity of xmit capacity.
              I.e. as you make the granularity of xmit allocation finer
              and finer, the queueing delay goes up and vice versa.
         <li> Buffering: trade off buffer requirements vs. granularity
              of xmit capacity.
       </ul>
  <li> Can combine framing with other traffic-mgmt strategies for
       delay-tolerant traffic (put into type 0 frames, don't need to
       service according to framing strategy).
  <li> Related paper describes how to balance stat. mux'ing of
       time-framing with packet loss induced by admission control.
    
</ul>

<h2>Relevance</h2>

Nice statistical multiplexing argument with some mathematically
developed bounds on queueing delay and buffering---provided you can do
strict admission control and that your traffic fits well into these
constant-frame-size, constant-bit-rate classes.  (Seems like you could
dynamically change the class of a connection if needed, but this is a
whole new layer of scheduling and is not even mentioned in the paper.)

<h2>Flaws</h2>

<ul>
  <li> Admission based, so what if senders try to be malicious -- does
       algorithm make sure badness doesn't propagate past first switch?
       Even so, doesn't that make life miserable for other users of the
       first switch?
  <li> Similarly: compatibility/interoperability w/existing schemes?
       (Author talks about <i>coexistence</i> with them, but that's a
       much weaker notion)
  <li> Bursty traffic loses.  Statistical mux'ing is only for non-RT
       traffic (though this may be an acceptable soln)
</ul>
<hr>
<a href="index.html"><i>Back to index</i></a>

</body></html>
@
