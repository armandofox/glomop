head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	97.03.03.16.47.23;	author fox;	state Exp;
branches;
next	;


desc
@@


1.1
log
@*** empty log message ***
@
text
@<html>
<title>
ARPANET Routing
</title>
<body>
<a href=index.html><i>Back to index</i></a>
<h1>
The New Routing Algorithm for the ARPANET
</h1>
<strong>
John M. McQuillan, Ira Richer, Eric C. Rosen
</strong>

<p><b>One-line summary:</b>
Shortest-path-first (based on delay) routing trees are constructed and
updated to direct routing, with various precautions taken to insure that
all nodes' databases are consistent.
</p>

<h2>Overview/Main Points</h2>

<ul>
  <li> Problems with older algorithm:
       <ul>
         <li> Entire routing tables were transmitted; long packets
              screwed up other traffic
         <li> Each node used local info only to make routing decisions,
              so inconsistencies in routing tables might develop
         <li> Lack of stability: sometimes too slow to respond to
              connectivity changes, sometimes overreacts for minor
              changes
         <li> Queue length is a poor indicator of line delay and poor
              predictor of packet latency
       </ul>
  <li> New algorithm: build tree of the network using shortest path
       first; updates affect subtrees and are propagated only to nodes
       in those subtrees.
  <li> Takes 10 sec to take a measurement (by averaging many packet
       delays), so this is an upper bound
       on how frequently updates can happen
  <li> Transient loops possible, but in practice appear to be short
       lived (only for packets already in transit when an update is
       received)
  <li> New node additions or node removals are implicitly recognized as
       connectivity changes
  <li> Updates are only observed if the newly measured average delay
       differs from the previous value by some threshold T; if they
       don't, T is reduced by d.  Initially they set T=64ms, d=12.8ms.
       <b>Goal was</b> to allow system to react quickly to large changes and
       slowly to small ones.
  <li> Updates sent by "flooding", i.e. transmit on all lines except the
       one on which it was received.
  <li> Consistency/stability: goal was to insure all nodes have the same
       routing info database.  The collection of safeguards seems to
       suggest a remarkably brittle system:
       <ul>
         <li> Each node must generate at least 1 update per minute.
         <li> New node cannot come up till it has heard updates from all
              other nodes.
         <li> Serial numbers on updates are used to prevent "stale"
              updates from being recognized when they are finally
              delivered to a node that was temporarily down.
         <li> Network partition conditions cannot be lifted until
              updates from each partition have flowed into the other.
       </ul>
  <li> Performance: SPF running time is proportional to size of affected
       subtree; but average subtree size is equal to average hop length
       from root to all nodes.  Therefore, running time grows with
       netork hop length, which generally grows slowly ((log N)/(log c)
       for N-node network with uniform connectivity c&gt;2).
  <li> Testing: stress the algorithm, running it on the actual ARPANET!
       Can't test algorithms that way these days!  (Authors write that
       their experiments can't be called "scientific" since other users
       were using the network at the same time!)
  <li> Deficiency of old algorithm remedied by new one: used to take
       several seconds to resolve a routing loop or pathology, now it
       takes msecs.  Compare with <a href="paxson.html">Paxson's
       measurements</a>  of modern Internet!
  <li> Old algorithm took less memory, but authors assert that's not
       very important.  Perhaps so, in the days when the dedicated
       routers were the IMP monstrosities.
</ul>

<h2>Relevance</h2>

The humble beginnings of modern routing-update protocols.  Like other
papers from the early days (except for the Cerf and Kahn paper), it's
somewhat jumbled and hard to read.

<h2>Flaws</h2>

<ul>
  <li> Scalability: each node maintains full network map, and updates
       are broadcast.
</ul>
<hr>
<a href=index.html><i>Back to index</i></a>

</body></html>
@
