head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	98.05.27.23.46.47;	author fox;	state Exp;
branches;
next	;


desc
@@


1.1
log
@*** empty log message ***
@
text
@Trip Report for CHARME '93 (Arles, France, 5/23/93--5/26/93)
Armando Fox & Chris Jones
(Correct HARdware design MEthodologies)

CONTENTS: (search for >> to page through sections)
---------

>> What is CHARME
>> Pointers to Documents
>> Notes about Attendance
>> Notes about Formal Verification
>> Short Summaries of Selected Papers
>> Discussions of Selected Papers

>>WHAT IS CHARME
----------------

CHARME is a project focusing on formally-correct hardware design
methodologies.  Current participants are IMAG, IMEC (Belgium),
Polictecnico di Torino, Univ. of Frankfurt, Univ. de Provence
(Marseilles), and Univ. of Strathclyde (Scotland).  CHARME'93 is the
seventh work-in-progress presentation of the efforts of researchers at
these organizations.

>>POINTERS TO DOCUMENTS
-----------------------

The following documents are available in Armando's or Chris's cubicles:

- Conference proceedings (published as Lecture Notes in Computer Science
   # 683, Springer-Verlag)

- Attendance list with email contacts

- Selection of papers not in proceedings about Formal Verification by
   Signal Flow Graph Tracing 

A number of other TR's and work-in-progress papers are on their way by
email from the authors.


>>NOTES ABOUT ATTENDANCE
------------------------

Academia was better represented than industry, with most of the
theoretically-interesting work being supported by fairly simple
examples.  There were notable exceptions in which the research at least
addressed what problems might arise in scaling the results to "real"
problems.  There were also a number of reports describing
successfully-implemented, nontrivial designs, particularly non-pipelined
microprocessors, that are provably correct.

There was a lot of interest in what Intel was doing on current projects
with respect to formal verification.  (Don't worry, we didn't leak
anything.)  A number of participants eagerly thrust technical reports at
us and encouraged us to send email so they could send their latest work.
(A list of email contacts is available in Armando's/Chris's cubicle.)


>>NOTES ABOUT FORMAL VERIFICATION
---------------------------------

To say that an implementation is "provably correct" means that it can be
formally shown that the implementation meets the specification.  This
requires some language theory, as follows:

1. The specification must be unambiguously expressed using a suitable
   "source language".  Such a language typically makes statements about
   mathematical objects that model "processes" or "transactions".  

2. The target language of the specification must have similar
   unambiguous semantic properties.  This is a big problem with VHDL,
   which is an informal, sloppily defined language.

3. The transformations by which the specification in a high-level
   (process-algebra-like) language becomes an implementation in a
   low-level (VHDL-like) language must be provably
   correctness-preserving, i.e. they must preserve the semantics of the
   operations described.  This means that the semantics of all the
   languages involved must be unambiguous.

The focus of papers presented fell into these broad categories:

A. Language theory in support of the above

B. Methodology for design for verifiability (DFV), by imposing (e.g.)
   coding guidelines that make it possible for verification to be done
   by largely automated means

C. Actual implementations of correctly-derived designs

D. Techniques to expedite the formal verification process, such as
   representation of design elements (BDD's, asynchronously
   communicating subfubs, etc.) at higher levels of abstraction.


>>SHORT SUMMARIES OF SELECTED PAPERS
------------------------------------

The "abstracts" below are not the actual paper abstracts, but rather my
own paraphrased summary of what I got out of the presentation/paper.
The highlights/lowlights (marked with + and -) are my own opinions.

***************************************************************************

** A Petri Net Approach for the Analysis of VHDL Descriptions
** S. Olcoz (Tecn. Grupo INI), J. Colom (U. of Zaragoza, Spain)

ABSTRACT: Detection of undesirable behaviors (esp. deadlocks) in VHDL
code can be done by representing the control flow as a Petri Net
(place/transition net describing preconditions necessary to reach a
given state and postconditions that are created as a result of entering
the state).  The translation is accomplished by composing Petri net
"building blocks" representing four basic VHDL structures: sequences,
conditionals, procedure calls and loop/next constructs.

Structural analysis of the Petri net looks for marking-invariant
transitions, i.e.  transitions in the net which are "safe" in that they
cannot contribute to deadlock conditions.  Non-invariant transitions are
subjected to reachability graph analysis to determine whether a deadlock
condition does in fact exist.

+ Designers/VHDL coders need not understand the underlying theory to use
  the methodology.

+ Petri net analysis algorithms (linear programming) are well understood
  and computationally efficient.

+ The size of the Petri net is large, but linear with respect to the
  VHDL code size.

- The nets model only control flow, not data flow, so deadlocks that
  depend on data values cannot be detected by this kind of analysis.

- Timing constraints are not modelled.

***************************************************************************

** Strongly-Typed Theory of Structures and Behaviours
** Keith Hanna & Neil Daeche, (U. of Kent, Canterbury)

ABSTRACT: Traditionally, an implementation is given only in informal
terms (e.g. schematic), so the problem of determining the formal
behavior of the circuit from its component parts can only be approached
informally.  This is inadequate for formally verifying anything other
than ideal, two-valued logic (e.g. tristate or precharge/discharge
logic).  

This paper uses type theory to define types that permit the
implementation to be formally specified (allowing a formal behavioral
specification of the circuit given the behavior of its component parts),
and that allow "well-formedness" predicates based on a particular
process or technology to be formally applied to the implementation.
("Well-formed" may be defined to mean, e.g., that only one driver drives
a tristate bus at any given time, that the type of each output port
matches the type of the node to which it is connected, that there are no
combinational cycles, etc.)

The authors derive a strongly-typed theory of structures and behaviors
(TSB) using the VERITAS logic system, and show how TSB may be translated
to an extended VHDL in which each module's behavioral as well as
structural aspects are specified.  "Behavioral aspects" means that the
"types" of the ports, e.g. semantic information about what the component
"does", is part of the description.

- Although the authors claim that their theory is useful for verifying
  circuits more sophisticated than simple 2-state logic, the only
  examples they provide are for 2-state logic devices (gates).

- The authors acknowledge that the main benefit of the theory may be as
  a formal foundation for development of more rigorous HDL's.

- The authors have actually computed only toy examples, and do not know
  how computational needs scale with problem size.

+ Compared to current ad-hoc HDL's, strongly-typed HDL's would permit
  the kind of static checking that is currently done by software
  compilers.


***************************************************************************

** Denotational Definition of a Synchronous VHDL Subset
** Dominique Borrione & Ashraf Salem (IMAG/Artemis)

ABSTRACT:  Defining a denotational semantics for a language provides a
formal mathematical basis for proving correctness of programs in that
language.  This paper describes DS for P-VHDL, a synchronous subset of
VHDL used in the PREVAIL project (q.v.).  P-VHDL imposes a particular
style on VHDL coding to facilitate syntactic recognition of certain VHDL
constructs.  

Denotational semantics for a language make the language
implementation-independent, gives an unambiguous interpretation to
elements of the language, and allow the language elements to be operated
on as mathematical objects.  Defining a denotational semantics requires
an abstract syntax (e.g. syntactic domain combined with BNF-like
description of the language), a semantic domain, and evaluation
functions.  The semantic domain of P-VHDL consists of "value spaces" for
signals (current value), registers (current and next values), clock
signals (rising/falling edges as triggers), and abstract variables.

- P-VHDL allows Wait, Stable and Event only on single clock.

- No delayed assignments because it introduces a notion of "prospective"
  time, which cannot be captured by strict causality.

+ Work is in progress to alleviate the above two restrictions.

- Descriptive style of coding must be observed by all VHDL writers in
  order to guarantee adherence to DS.

+ Authors acknowledge that language people really hate VHDL because it
  was basically written down without regard for strictness, but since
  it's in widespread use it is valuable to establish a DS for it.

***************************************************************************

** Temporal Analysis of Time Bounded Digital Systems
** Alan R. Martello & Steven P. Levitan (Univ. of Pittsburgh)

This paper discusses a method for formally verifying properties such
as mutual exclusion and absense of glitches in digital circuits.  By
discretizing the time domain and assigning (min,max) time delays to
each gate in a circuit, every possible combination of signal values
over time is generated and can be checked to verify that certain
properties hold.

The major drawback to this approach is that it is, at worst,
hyper-exponential in complexity to determine all of the possible
signal combinations.  Although it tends to be *only* exponential in
practice, it is still unlikely to be practical for larger circuits.

One can imagine restricting the discretization of time to a
cycle-based approach, perhaps allowing some formal verification of
protocols, though this is not discussed in the paper.

***************************************************************************

** Restricted Hierarchical Ordered BDDs (Meta-BDDs)
** Stefan Horeth (Univ. of Frankfurt)

This was a very interesting presentation for the BDD-literate.  Most
of the space/time limitations of manipulating BDDs occur in
intermediate representations containing huge numbers of nodes.  This
approach allows BDDs to be hierarchical (a node in a BDD can represent
another BDD), which reportedly can reduce the size of the data
structure by about 30%.

Unfortunately, the paper for this talk was not included in the
precedings.  We should be receiving a copy from the author soon.


***************************************************************************

** Verification and Diagnosis of Digital Systems by Ternary Reasoning
** Ayman Wahba & Einar Aas (IMAG/Artemis)

This paper focuses on some algorithms for isolating the cause of a
logic bug when mismatches between a spec (K-map) and an implementation
(gates) is found to exist (a la SALT).  Armed with the knowledge of
what are typical design errors (missing inverters, wrong gate type,
etc), it is often possible to quickly pinpoint the design bug.

Algorithms for the most common design errors are included in the
paper.  Unfortunately, this is limited to single-gate errors, as it is
much more difficult to diagnose multiple-gate design errors.

***************************************************************************

** Advancements in Symbolic Traversal Techniques
** Gianpiero Cabodi & Paolo Camurati (Politecnico di Torino)

More fodder for the BDD afficiando.  Currently, there are two widely
used approaches for manipulating FSMs as BDDs: Transition Relations
and Transition Functions.

The Transition Relation describes the sequential behavior of the FSM
by listing the (current,next) state couples independently of the
inputs.  This can be described by its characteristic function which is
represented as a BDD.

For example:

        {00}---->{11}<-----{01}

can be represented as the expression: !s1 ^ s0' ^ s1'
(i.e. any state with s1 = 0 can transition to state s0 = 1, s1 = 1)

This approach has many advantages over Transition Functions, but often
requires very large intermediate BDDs, limiting its usefulness.  This
paper shows a method for vastly reducing the size of the intermediate
BDDs, allowing larger problems to be solved.

***************************************************************************

** Calculational Derivation of a Counter with Bounded Response Time
** Joep Kessels (Philips Research Labs, Eindhoven, Netherlands)

This paper shows an example of how transformational design methods can
be used to derive a formally correct circuit (an asynchronous counter
in this case).  The design is recursive (a counter with a large enough
period consists of an extension cell and a subcounter with a smaller
period).  Starting with a recursive definition, correctness-preserving
transformations are applied to derive the final design.

The actual derivation of the counter takes up most of this paper, so
it is fairly dry reading.  However, the concepts of transformational
design are discussed in several sections and are probably worth
perusing.

***************************************************************************


>> DISCUSSIONS OF SELECTED PAPERS
-----------------------------------------

** Algebraic Models and the Correctness of Microprocessors
** Neal A. Harman & John Tucker (Univ. College of Swansea, UK)

By modeling a microprocessor algebraically at two different
abstraction levels (ISA and implementation) it is possible to prove
that the implementation is correct by proving that mapping functions
exist which map the state and timing of one model into the state and
timing of the other.

For example:

1) Programming Model (ISA, Archsim, ...)

        T = time (instruction counter)
        Cpm = State of machine

        PM : T x Cpm -> Cpm

        PM is a function which maps an initial state and a time count
        into a resultant state (i.e. executes T instructions to
        generate the new Cpm).

        Notes: Cpm includes system memory.
               Assumes formal specification of ISA semantics is known :-)


2) Abstract Circuit Design (RTL)

        S = time (cycle counter)
        Cac = State of machine (much larger than Cpm above)

        AC : S x Cac -> Cac

        AC is a function which maps an initial state and a time count
        into a resultant state (i.e. executes S cycles to generate the
        new Cac).

        Notes: Cac includes system memory.
               Would be very nice if AC could be derived from HDL

What we would like to find are mappings T->S, Cac->Cpm, and Cpm->Cac
so that the following diagram commutes:

lambda : T x Cpm -> S
alpha  : Cpm -> Cac
pi     : Cac -> Cpm

                    PM
        T x Cpm  -------> Cpm
        |  / |             ^
        | /  |             |
 lambda |/   | alpha       | pi
        |    |             |
        V    V             |
        S x Cac  -------> Cac
                    AC


This diagram says that if we take the "architectural" state Cpm and
map it into "real" state Cac, clocking the implementation S cycles
(given by lambda) to execute T instructions, we must end up in a state
which can be mapped to Cpm (by throwing away the "non-architectural"
stuff).

The design is formally proven if all of the above mappings (including
AC and PM) can be defined.

You might see some resemblance between this diagram and how we use the
RTL and Archsim with the Checker.  The Checker does the state mapping,
dynamically translating RTL cycles into instruction counts.  However,
nothing is really formalized (not even the spec).

The real kicker, if you haven't guessed already, in trying to actually
use this method is that is is nearly impossible to figure out what
lambda is in a microprocessor such as the P6 due to the fact that it
is dependent on the entire state of the system.  How many clocks does
it take to do an ADD macroinstruction in the P6?  It just depends....


** A Methodology for System-Level Design for Verifiability
** P. Camurati, F. Corno, P. Prinetto (Politecnico di Torino, Italy)

DISCUSSION:  A DFV methodology limits designers' freedom to guarantee
verifiability.  The authors propose a system-level DFV methodology that
treats separate HDL modules as asynchronous processes that may run
concurrently, and formalizes the interactions between them by requiring
them to be encased in specific extended-VHDL constructs.  

The thrust of the methodology is that, if individual modules written
using the methodology can be formally verified, the formalization of
intermodule interactions imposed by the methodology allows one to make
statements about the correctness of a system composed of such modules,
*without* having to re-verify the system.  [The authors do not address
how to verify individual modules.]

For example, the authors develop an MP bus controller by developing and
verifying a "bus control" module and a "CPU" module according to their
methodology.  They then show how the composition of the two modules can
be formally shown to comply with the spec.  The kicker is that they then
hang two more identical CPU modules on the bus, and show how the new
system can be proven correct without having to re-verify any of the
parts.  The key to being able to do this lies in the formal abstraction
of intermodule communication.  The flow of the methodology is as follows:

          predicate-       EVAL input-                 BDD package:
 VHDL --> transition  -->  description --> Process --> minimization,
          Petri nets       language        algebra     equivalence proofs

All translation steps except the first (VHDL to Petri-net) are
automated. The VHDL code must consist of legal VO-VHDL
(verification-oriented VHDL), a VHDL subset extended to include a
COMMUNICATION_CHANNEL type and explicit SEND and RECEIVE calls to effect
communication among modules.

Message "protocols" supported include call/return (wait),
multi-rendezvous (fence), set-and-forget (write latch), and
send-and-forget (momentary condition that is not latched).  A
communication channel must specify which protocol is used, what messages
may be exchanged, how to compose messages from multiple transmitters,
how to dispatch messages to receivers, and readers/writers of the
channel.

The authors used their system (called SEVERO; about 15k lines of C) to
verify the above example involving multiple CPU's on a shared bus, and
even found a bug (deadlock hole) in the protocol they implemented.
"Deadlock-free" and "liveness" proofs were derived in 38 and 1420
seconds, respectively, for a 2-CPU and 3-CPU system.  

The authors do not discuss complexity so it's hard to tell how the
verification time scales with problem size.  However, they presented one
of the few approaches which acknowledges that most industrially-
interesting problems are too large to be attacked by "conventional"
formal verification techniques.  By defining a top-to-bottom methodology
that supports automated formal verification at each step, the authors
permit leveraging of unit-level verification directly to system-level
verification, which in my opinion is the main strength of their
research.  Their methodology also permits the modelling of some
concurrency by treating separate modules as independent process objects,
in contrast to many other "correct-by-construction" papers (see Windley,
Claesen, Bose et al., Harman et al. in these proceedings) which model
the data and time abstractions orthogonally and do not permit one to say
anything about concurrency.

Send email to get the most recent results (Paolo Camurati
<camurati@@polito.it>); version in proceedings is several months old.

** A Theory of Generic Interpreters
** Philip Windley (U. Idaho/Brigham Young U.)

DISCUSSION:  The "interpreter model" uses a state transition system to
describe the operation of a microprocessor.  The Theory of Generic
Interpreters (GI) provides a methodology for formally deriving definitions
and lemmas about this model.  

The interpreter model assumes a central control point for computation; a
particular instruction is selected, effecting a state transition, and
the cycle begins again.  Note that temporal concurrency is not modelled
(the author claims he's working on it), so the theory of generic
interpreters currently says nothing about pipelining or other
concurrency.  

Microprocessor design can be viewed as successive levels of abstraction,
from the high-level spec to the structural spec.  Each level has its own
notion of passing time.  The GI includes a function that maps time in
one level of abstraction to time in another, e.g. to model the breakdown
of a single assembly-level operation into many uops; this function makes
use of an abstractly-defined predicate G that is true exactly when the
mapping occurs (e.g. exactly at end-of-macro).  (Since the model doesn't
support concurrency, I didn't ask how the predicate could be defined for
a multiple-retirement implementation.)

The theory is used to derive theorems and predicates about important
properties of the model:

* instruction correct -- state change caused by an operation at one level
is identical to state change caused by (possibly a sequence of)
operations at the next level when the predicate G is true.

* output correct -- observable outputs are the same for corresponding
states of two levels.

* liveness -- for every level, there is a finite time between beginning
of cycles.

There is also a composition operator, which composes two GI's
related in such a way that the implementation of one is the
interpretation of the other.  That is, it "collapses" two levels in the
interpreter hierarchy.  The resulting structure is itself a GI that
provably does the same thing as the two that were composed.  Composition
is shown to be associative and correctness-preserving.

Since the theorems and proofs are developed using the HOL theorem
prover, it is presumably the case that a designer could, at whim, "run"
the theorems on a design to determine whether two levels of abstraction
during the design are correspondent.  Unfortunately, no examples are
offered, nor does the author address how the system might be integrated
with existing design methodologies/environments.  However, the theory
has been used to formally verify a load-store microprocessor (which
presumably is a non-pipelined fully microcoded single-issue machine).

In all, an interesting academic exercise that should become more
interesting if the GI theory is extended to handle concurrency.  


** D-FM9001: Derivation of a Verified Microprocessor
** Bhaskar Bose, Steven Johnson (Indiana Univ., Bloomington)

DISCUSSION: The paper describes the formal derivation and automated
implementation of a 32-bit load-store uP using the Design Derivation
System (DDD).  The D-FM9001 is based on the FM9001 (a previous,
mechanically-verified uP implementation).  The implementation itself
uses a large FPGA for the datapaths and SRAM register file.  (Yes, these
are two separate chips; but this was a prototype project so we overlook
this implementation detail.)  Individual datapath components were highly
optimized and their behavioral descriptions isolated using DDD's
abstraction mechanisms.  Most of the final design was mechanically
derived; those parts which were not, were verified using Boolean
equivalence methods.  Incidentally, the design worked the first time.
The architecture includes 16 registers, 16-function ALU, 5 addressing
modes, conditional assignment and 32-bit addressing.

The high-level specification of the FM9001 is a set of 6 recursive
functions written in a LISP-like syntax, defining the part's behavior at
the programmer level.  (It fits on one page -- not a really complicated
architecture.)  A set of transformations converts this spec into a
netlist.  

The first set of transformations moves control points from inside to
outside of high-level behavioral specifications.  For example, the
original "procedure call" for an ALU-op was something like:

        (alu-op (if (register-direct) 
                    (do-register-direct-op)
                    (do-memory-reg-op)))

This was  transformed to move the conditional outside the "call":

        (if (register-direct)
            (alu-op  <register-direct-args>)
            (alu-op  <memory-reg-args>))

This allows decision points to be moved into a central "control"
component, rather than being embedded in the architecture (in this case,
inside the ALU itself).

The second set of transformations imposed serialization on the inherent
parallelism in the functional-language specification of behavior.  For
example, read and write to the register file within a single operation
need to be serialized.

The next two sets of transformations decompose the behavioral spec into
a control and a datapath/structural component, and encapsulate component
operations into logical modules.  This permits individual modules to be
verified and the modules to be integrated later.

The only manual steps reported during the transformations were the
merging of the memory and register-file data bus, and the combination of
the ALU and incrementor/decrementer into a single component (which had
to be reverified).

The total elapsed CPU time (Sparc2) for derivation of the netlist from
the high-level spec was 30 minutes, and the netlist itself was 69Kbytes
in size.  Not exactly a Pentium(tm), but it's interesting to show that
this can be done even for a small example.  Incidentally, the author and
I were discussing what targets in industry might be amenable to formal
verification techniques.  He seemed to think that trying to use formal
verification on complex parts was not the best idea, since current FV
techniques are too computationally intensive and not well enough
understood (esp. as regards temporal concurrency).  On the other hand, I
thought that would be where the most interest would be generated, since
really simple parts can probably be verified adequately without the aid
of FV.  The author pointed out that formally verifying parts of a design
is theoretically worthless unless the whole design can be formally
verified.  I pointed out that while that was certainly true, I could
think of cases where formal verification of parts of our design would
make us feel much better.

The work presented in this paper is not yet mature enough to verify a
large complicated part, but it seems feasible to use it for verifying
subsystems inside of which there is no asymmetric temporal concurrency.
The authors say not a word about performance, but on the other hand not
everyone is designing for performance...I can imagine this kind of work
being very interesting to, e.g., NASA.

@
