head     1.1;
branch   1.1.1;
access   ;
symbols  initial:1.1.1.1 initial:1.1.1;
locks    ; strict;
comment  @# @;


1.1
date     97.02.27.00.18.40;  author fox;  state Exp;
branches 1.1.1.1;
next     ;

1.1.1.1
date     97.02.27.00.18.40;  author fox;  state Exp;
branches ;
next     ;


desc
@@



1.1
log
@Initial revision
@
text
@<a href="index.html">Back to index</a>

<h1>Why the future of the Internet is not multimedia, and
other high heresies</h1>

Mike O'Dell, UUNET<br>
Multimedia seminar, 2/26/97
<hr>

The "long view": multimedia is not what the Internet will be about.
(Maybe not vindicated in next 3-5 years, but certainly in the long run.)

<h3>High heresy #1: the future of the inet is not multimedia</h3>

<ul>
  <li> not "just like" anything else
       <ul>
         <li> attempts to migrate traditional media to inet are
              failing. (radio is not a talking newspaper; TV is not radio with
              pictures.)  It's a new medium.
         <li> packets don't carry "sensory analog" traffic well
         <li> impications for e-commerce, e-advertising?
       </ul>
  <li> too expensive
       <ul>
         <li> long haul infrastructure too expensive; free unlimited
              bandwidth not coming (who remembers "power too cheap to
              meter"?)
         <li> fast access to <i>local</i> caches/content: maybe.  (Long
              haul is up to 3 orders of magnitude more expensive to
              deploy)  So @@Home's model may be viable.  Jury still out.
         <li>  <b>Corollary:</b> (Content providers will have to accept
              that in order for 
              their content to be seen, it will have to be cachable!)
         <li> "local" vs "long distnace" internet access???
       </ul>
  <li> technology growth
       <ul>
         <li> second derivative is wa positive. "If you
              aren't scared, you don't understand." [QUOTE]
         <li> UUNET-2000: 50 terabits; today: 5 gbits; look for 1000x
              growth over 3 years.
       </ul>
  <li> Voice: $250B "niche"; grows only with human population, driven by
       population demographics (like other "human centric" businesses).
       Little value in adding voice quality.
</ul>

<h3>Fundamental shift in bandwidth consumption</h3>

<ul>
  <li> Formerly, growth driven by "mothers day"
  <li> Now: hungry silicon cockroaches!  (computing power that attracts
       communications bw)
  <li> short,fast, bursty vs. long,slow,smooth channel use
  <li> limiting factor for growth: basically, rate of melting sand!
  <li> pecking order
       <ul>
         <li> fax machines, cellphones: blew out the North Amer
              Numbering Plan
         <li> PC+modem: blowing out switched capacity
         <li> inet backbones: eat long haul capacity
         <li> webphones and digital daytimers:  eat wireless capacity?
              (huge fraction of cell phone calls are to set up other
              meetings, etc., not conversations!)  "Network externality"
              effect will cause this usage to overwheml multimedia.
         <li> <b>capacity is getting used up as fast as it's provided</b>
       </ul>
  <li> implications
       <ul>
         <li> web content will be examined by robots, only shown to
              humans <i>after comparison shopping!</i>  Automatic
              aggregation services willdominate.
         <li> therefore existing advertising models are broken...
         <li> cockroaches will be empowered by owners to spend money.
       </ul>
  <li> conclusion: follow the money
       <ul>
         <li> Comm networks 21st c. will be built for cockroaches
         <li> human/cockroach symbiosis
       </ul>
</ul>

<h3>Heresy #2: multicast everywhere</h3>

RSVP and classic multisource mcast--no way.
<ul>
  <li> bad scaling; "The only problem is scale; all other problems inherit
       from that."  (O'Dells Problem Statement) [QUOTE]
  <li> no business model.  (Uunet is spending &gt;$300M
       next year for infrastructure! Similarly AOL...)
  <li> parts may be salvageable for large scale use
</ul>

<h3>Heresy #3: all you need is IP routers: guided tour of UUNET</h3>

IP-router-only problems:

<ul>
  <li> No traffic mgmt except on toy topologies
  <li> classic IP dest-only fwding induces "super-aggregation" f IP
       traffic; can't disaggregate them.  Result is unbalanced network;
       Controlling traffic "spread"
       is just not feasible -- only realizes small percentage of network
       capacity.
  <li> capacity and bandwidth are different
       <ul>
         <li> hard to add "targeted" capacity
         <li> BW+BW=capacity; but capacity is "incoherent" (basically,IP can't
              convert it into ordered-delivery bandwidth)
       </ul>
</ul>

UUNET architecture:

<ul>
  <li> deep systemic redundancy
       <ul>
         <li> redundancy in the switches (implementation)
         <li> redundancy in routing maps (architecture)
         <li> little redundancy in IP routers
         <li> all hardware in "lights-out, hands-off" locations, costs
              at least $1K to get a human to go do something.
       </ul>
  <li> cost of ownership (operating cost) vs.  capital.  Be careful
       which you optimize!
  <li> 4 layer network, top to bottom:
       <ul>
         <li> collector networks: a lot of muxing to bring customer IP
              traffic to network core
         <li> IP routing: fully redundant mesh; no customer-specific
              state in core routers; protected at edges only (route
              filters).  Optimized for fast IP forwarding, and that's
              all.  Two full-meshes with spoke "leaves" interconnected
              in pairs. 
         <li> transit switching: map large traffic flows onto traffic
              fabric in a way that's <i>invariant</i> to IP topology; "surgical
              precision" for adding transmission capacity.   <b>Full
              dynamic routing with constraints.</b>
         <li> transmission facilities (TDM bandwidth, telephony-to-TTL);
              OC12c, OC48 "soon" (year-end 97)
         <li> <b>Observation:</b> traffic flow engineering is an
              economic optimization problem.  Collapsing the above
              layers removes most of the knobs that allow this problem
              to be solved.
       </ul>
  <li> "Metro architecture" (now being deployed):
       <ul>
         <li> OC-12 "metro rings" (july 97); above "superhubs" are situated
              around the ring (OC48: year end 97)
         <li> applies backbone architecture recursively
         <li> regional traffic engineering
         <li> segregation of data, control, routing "planes"; no reason
              to collapse these functions into one box
       </ul>
  <li> "Massively Parallel backbone" (tm)
       <ul>
         <li> 500 Gbits trunk, 2-10 Gbits strands, 20-50 Tbits aggregate
         <li> building blocks: 16-port OC48c switches, DWDM (wave
              division muxing) puts 
              multiple OC48c on a 
              fiber, wavelength-agile lasers on line modules
         <li> take the OC48c switches, stack them up, stack another
              bunch of them up perpendicular, and you get something that
              looks like a 3D version of the Myrinet crossbar using
              OC48c.  Whoa.
       </ul>
</ul>

<h3>Intersting open problems... (from Q&amp;A session)</h3>

<ul>
  <li> Simluation and modeling: traditional network modeling/simulation
techniques break at this scale.  What do you measure/model? What
behaviors or variables are interesting?  The "phenomenology" of
this scale of packet network is just not well understood.  (You
<i>can</i> observe things like "large Net events": Olympics,
Superbowl, new release of Netscape...)<p>

  <li>  "Internet weather report": what does it measure?
  <li> "Why (internet) caches are impossible"? (someone else's talk)
  <li> Someone asked "What do you think AOL's problem is?"  He declined
       to comment, saying "There but for the grace of God..."
</ul>



<a href="index.html">Back to index</a>

<hr>
<address>fox@@cs.berkeley.edu</address>
@


1.1.1.1
log
@
@
text
@@
