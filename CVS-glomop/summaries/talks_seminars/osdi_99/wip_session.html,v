head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	99.02.26.17.30.08;	author gribble;	state Exp;
branches;
next	;


desc
@@


1.1
log
@more good stuff - osdi 1999
@
text
@<html> <head>
<title>WIP session</title>
</head>

<body>
<h2>WIP Session</h2>

<h2>Multi-Resource Lottery Scheduling in VINO - Sullivan, Haas, Seltzer</h2>
<ul>
     <li> currency funds processes - encapsulate resource rights, scheduling
     <li> vino:  resource-specific tickets (disks, cpu, memory...)
     <li> ticket exhanges:  allow processes to barter (trade disk for CPU)
     <li> e.g.: web server virtually hosting 2 sites.  one has large
	  working set, trade off its cpu for second set's memory
     <li> per-currency brokers and extensibility mechanisms
     <li> Q:  Amoeba and bank server - been there, done that
</ul>

<h2>QoS in Eclipse - Bell labs</h2>
<ul>
     <li> adds resource reservations and QoS guarantees
     <li> "/reserv" file system shows resources, and shows reservations and
	  sub-reservations in FS hierarchy
     <li> all usual benefits of QoS guarantees - isolation, predictable
	  performance, etc.
</ul>

<h2>Long-term FS read performance - Roselli, Matthews, Anderson</h2>
<ul>
     <li> An evolved FS is radically different from a newborn FS.
	  Stabilization in their traces takes <b>at least</b> ~10 days.
     <li> Clustering:  semantic (FFS), temporal (LFS), historical (new)
     <li> Q: suggestion - track reads that "take too long" according to user
     <li> Q: compare with Stahlin's reorganization scheme from 1982.  Goal:
	  move hot data to middle of disk using historical data
</ul>


<h2>High-performance Distrib objs over SAN - microsoft research</h2>
<ul>
     <li> millennium falcon: VIA cross DCOM, target COTS apps + transaction
	  apps + high-performance scientific approach
     <li> DCOM overhead dominates (no big surprise).  Fix marshalling
	  (scatter-gatter so no data copying), remove redundant RPC legacy
	  code from DCOM layer. 
</ul>


<h2>Pebble Component-Based OS - bell labs</h2>
<ul>
     <li> goal: tookit for generating specialized operating systems out of
	  run-time replaceable components
     <li> claim: only non-replaceable (at run-time) piece is
	  context-switching kernel
     <li> portals - caller/callee specialized kernel gateways between os
	  components.  Component: device driver, FS, interrupt dispatcher,
	  etc.
</ul>

<h2>Cellular Disco - Govil, Teodosiu, Haung, Rosenblum</h2>
<ul>
     <li> problem: system software lagging for scalable SMPs.  Poor fault
	  containment, poor scalable resource management.  Solution:
	  virtual clusters - best of clusters and SMPs.  Turn SMP into
	  cluster by dedicating multiple nodes to one OS on top of the
	  Disco VM layer.
     <li> 
</ul>

<h2>PerDIS</h2>
<ul>
     <li> WAN distributed/replicated data store with transactions,
	  transparency, security, ...
     <li> Uses DSM (over wide area!!) to give transparency, garbage
	  collection
     <li> <a
	  href="http://www.perdis.esprit.ec.org">
	  http://www.perdis.esprit.ec.org</a> for report.
</ul>

<h2>Resource Management in a Multi Computer System (MCS) - HP labs</h2>
<ul>
     <li> Layer on top of os on top of set of nodes in SMP.  Enables global
	  resource sharing.
     <li> challenge: integrating global resource sharing with local OS.
	  (Device drivers, kernel hooks, ...).  Integrating policies.
	  Making it highly available.
     <li> simplifying assumptions:  near-uniform memory access.  Don't want
	  single system image.  Optimize for select subset of apps.
</ul>

<h2>ISTORE - Brown, Oppenheimer, Patterson</h2>
<ul>
     <li> argument for storage appliances - customized for appk,
	  self-monitoring and adaptive.
     <li> software: toolkit.  hardware: integrated devices with
	  self-monitoring.
     <li> monitoring data stored in system DB
     <li> views over data, and triggers
     <li> policy expressed as integrity constraints.  system:  transform
	  contraints into views, triggers, code templates.  claim:
	  feasibile for common things.
     <li> example: invariant - system must maintain 3 replicas of all data
	  objects
	  <ul>
	       <li> view:  disks' health status
	       <li> trigger: disk death, invoke adaptation code
	       <li> adaptation code: lock object, perform byte copy to
		    optimal disk, unlock disk, ...
	  </ul>
     <li> hardware is "virtual DB" providing views and triggers
</ul>

<h2>SafeThreads: New Abstraction of Control and Protection - Masahiko
Takahashi and Kenji Kono</h2>
<ul>
     <li> Threads are fast, but no VM protection.  Fix that.
     <li> multi-protection page table: multiple columns, each associated
	  with protection domain inside of a page
     <li> allocate page table for each safe thread.  context switch implis
	  only switching TLB
</ul>

<h2>Fast and Predictable Automatic Memory Management for OSs - U of Utah</h2>
<ul>
     <li> Java doesn't give you system software properties - long running,
	  reliable, time constraints
     <li> ex: garbage collection - unpredictable, slow.
     <li> partition heap into number of local heaps, inside each of which
	  is a number of objects.  This is an approximation of stack
	  allocation of objects.
     <li> measure object lifetime information to infer future object
	  lifetime.  Static analysis can help you know when to deallocate
	  local heap.
     <li> allow programmer to give system hints about memory behaviour and
	  object liftime to allow system predictions to be accurate and
	  deterministic.
     <li> Q: reference count!  (Rob Pike loves inferno.)
     <li> Q: ultimate programmer feedback - free the memory!
</ul>

<h2>Enriching the FS &lt;--&gt Storage System Interface - Roselli,
Matthews, Anderson</h2>
<ul>
     <li> high-end disk systems - RAID, Petal, ..., .  Complex (hot
	  swappable, load balancing, ...), do logical
	  to physical block mapping.  FS still believes its on single disk.
     <li> storage system - loses semantic information that FS have.  E.g,
	  lifetime locality, access locality, inter-file associations.
     <li> 
</ul>

<h2>Agile: Hierarchically Extensible Security Policy Architecture - U Utah</h2>
<ul>
     <li> Flask: separates security policy an dmechanism.  Label all
	  objects with integer Security IDs (SIDs)
     <li> hierarchy of policy deciders.  refine decisions by consulting
	  children.
     <li> Q: hierarchical security vs. ring structures.  Problem with rings
	  is escalation.  Why do it again, when learned that peer to peer
	  is better?
</ul>


<hr>
<address><a href="http://www.cs.berkeley.edu/~gribble/">Steve
Gribble</a> / <i><a   
HREF="mailto:gribble@@cs.berkeley.edu">gribble@@cs.berkeley.edu</a></i></address>
<!-- hhmts start -->
Last modified: Wed Feb 24 15:06:07 1999
<!-- hhmts end -->
</body> </html>
@
