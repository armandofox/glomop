head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	97.09.03.05.43.34;	author gribble;	state Exp;
branches;
next	;


desc
@@


1.1
log
@Added the superweb summary, and the index.html file for tracking summaries.
@
text
@<html>
<title>
Superweb
</title>
<body>
<a href="index.html"><i>Back to index</i></a>
<h1>
SuperWeb: Research Issues in Java-Based Global Computing
</h1>
<strong>
Albert D. Alexandrov, Maximilian Ibel, Klaus E. Schauser, and Chris
J. Scheiman
</strong>
<p>
<i>Summary by: Steve Gribble</i>

<p><b>One-line summary:</b>
SuperWeb is a Java-based &quot;Internet computing&quot; brokerage
infrastructure that allows hosts to register available computational cycles
with broker agents, and clients to access those available computational
cycles.  Security, trust, cost, communications, etc. are identified as
the main technical challenges to this infrastructure.
</p>

<h2>Overview/Main Points</h2>

<ul>
     <li> <b>SuperWeb infrastructure elements:</b>
	  <ul>
	       <li> <i>Hosts</i> offer their resources to the world by
		    registering them (along with resource consumption
		    constraints) to brokers.  This registration is treated
		    as a hint: the host may be in fact unavailable.  It is
		    not clear what entity enforces these constraints.
		    <P>
	       <li> <i>Clients</i> are the consumers of hosts' resources.
		    Clients can be individuals, large organizations that
		    need supercomputing power, network computers that have
		    no resources of their own, etc.  Consumption is based
		    on the execution of untrusted Java applets.  Clients
		    are responsible for parallizing and robustifying their
		    own applications.
		    <P>
	       <li> <i>Brokers</i> coordinate resource consumption across
		    clients and hosts.  Brokers are essentially a directory
		    of available hosts, bundled along with some economic
		    model for estimating cost based on supply and demand
		    and verification services to ensure hosts are up and
		    provide resources as advertised.  The brokers are
		    composed of:
		    <ul>
			 <li> interface - registration/directory service
			 <li> scheduler - assigns incoming tasks to
			      available hosts' resources
			 <li> accounting module - keeps track of charges
			      incurred by client and credits earned by
			      hosts
		    </ul>
	  </ul>

	  <P>
	  
     <li> <B>Technical challenges:</B>
	  <ul>
	       <li> <i>Interoperability</i>:  Problem is heterogenious
		    environments, solution is Java, mumble.
	       <li> <i>Execution speed</i>: Java is slow.  Solution is JIT,
		    fast interpreters, mumble.
	       <li> <i>Security</i>: Problem is that clients, hosts, and
		    submitted tasks are all untrusted.  Solution is
		    Java, mumble, encrypted algorithms,
		    mumble, replicated execution for reliability, mumble.
	       <li> <i>Communication</i>: Problem is that communication
		    speed across hosts in internet is slow and unreliable,
		    vastly limiting the cross-task communication that is
		    possible.  Solution: execute coarse-grained parallel
		    jobs or independent jobs only, raytracers,
		    key-cracking, mumble.
	  </ul>
	  
	  <P>
	  
     <li> Another claim is that although prototype is in Java (Javelin),
	  SuperWeb architecture could support arbitrary untrusted binaries
	  using something like SFI.
	  
</ul>

<h2>Relevance</h2>

It would be absolutely wonderful to harness all of those idle cycles out
there on the Internet.  Now is the time to design a resource brokerage
architecture for harnessing available wide-area resources;  superweb is a
decent first stab at identifying the issues.

<h2>Flaws</h2>
<ul>
     <li> Architectural flaws:
	  <ul>
	       <li> Are brokers trustworthy?  Why?  What can happen if a
		    broker is evil?
	       <li> There is no directory of brokers, so how do clients find
		    brokers?  It's the usual resource location bootstrap
		    problem.
	       <li> Nothing in the architecture can possibly reliably track
		    resource consumption.  Clients simply can not be
		    assured that they're getting enough bang for their
		    buck.  Maybe this is OK (e.g. Visa fraud model).
	       <li> It's unfortunate that I as an application writer only
		    get a list of hosts to execute on (effectively), as
		    opposed to some infrastructure tools for storing state,
		    rendezvousing, estimating job progress, receiving
		    notification of failed or aborted jobs.  This could be
		    remedied, IMHO.
	       <li> It's also too bad that I don't get help in writing my
		    parallel jobs, but this it's hard to provide a
		    parallelization toolkit that helps in the general case.
	  </ul>
     <li> Paper flaws:  way to wide and not nearly deep enough.  Again,
	  IMHO, the architecture they advocate and their associated
	  technical challenges are quite obvious, although it is nice to
	  have the list of problems explicitly written out.  None of their
	  suggested solution paths seem to be immediately applicable or
	  wholly satisfactory.
</ul>

<hr>
<a href="index.html"><i>Back to index</i></a>

</body></html>
@
