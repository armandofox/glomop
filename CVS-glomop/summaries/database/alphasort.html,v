head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	97.04.17.07.43.54;	author gribble;	state Exp;
branches;
next	;


desc
@@


1.1
log
@alphasort summary.
@
text
@<html>
<title>
AlphaSort
</title>
<body>
<a href="index.html"><i>Back to index</i></a>
<h1>
AlphaSort: A RISC Machine Sort
</h1>
<strong>
Chris Nyberg, Tom Barclar, Zarka Cvetanovic, Jim Gray, Dave Lomet
</strong>

<p>
<i>Summary by: Steve Gribble and Armando Fox</i>

<p><b>One-line summary:</b>
AlphaSort is a DataMation sort winner that optimizes the memory hierarchy
(stays on the processor cache as much as possible) and uses file striping
across disks to eliminate the reading-in and writing-out phase overheads of
the sort;  MinuteSort and DollarSort are recommended.
</p>

<h2>Overview/Main Points</h2>

<ul>
     <li> <b>Techniques</b>:
	  <ul>
	       <li> minimize cache-miss waits by:
		    <ol>
			 <li> QuickSort input record groups as they arrive
			      from disk - QuickSort has good cache
			      locality.
			 <li> sort (key-prefix, pointer) pairs rather than
			      records or pointers - reduces data movement.
			 <li> Merge QuickSort runs using
			      replacement-selection tree.  Since the merge
			      tree is small, you get good cache behaviour.
		    </ol>
	       <li> Comparison of 3 variants of quicksort.  Key sort wins -
		    especially if aline key/pointer on one cache line.
		    <ul>
			 <li> record sort - record array sorted in place;
			      much data movement
			 <li> pointer sort  - array of pointers is sorted;
			      many dereferences and random memory
			      references
			 <li> key sort - array of record-key,
			      record-pointer pairs is sorted.  Comparison
			      operators just examine keys in array.
		    </ul>
	       <li> shared-memory multiprocessor - one process per
		    processor.  Right away, run through VM to get pages
		    allocated - VMS's zeroing of allocated pages is nasty
		    slowdown.  Do in parallel with opening/reading of
		    files.
	       <li> disk bottleneck
		    <ul>
			 <li> must stripe, or die.
			 <li> one or two passes?  (i.e. keep first pass in
			      memory, or write to disk and do second pass
			      on disk?)  Tradeoff is cost of memory
			      vs. speed/cost of parallel array of disks.
			      Memory/onepass wins up to gigabytes of data.
			 <li> software striping needed to get big enough
			      array of disks so that reading in file is not
			      killer overhead.
		    </ul>
	  </ul>
     <li> recommendations:
	  <ul>
	       <li> minutesort: sort as much as you can in one minute.  Two
		    metrics are size (bytes), and price-performance
		    ($/sorted GB).
	       <li> dollarsort: sort as much as you can for a dollar.
		    Metrics: size (bytes), elapsed time (ms).  Count 3-year
		    maintenance price, normalize to time of sort.
	       <li> daytona (stock sort) vs. indy (do whatever you want,
		    e.g. NOWSort).
	  </ul>
</ul>

<h2>Relevance</h2>
Somewhat relevant - metric/benchmark for sorting.  Mostly a competition to
see who can do coolest optimization hacks.  Dollarsort/minutesort are
clearly more reasonable than Datamation sort.

<h2>Flaws</h2>

<ul>
     <li> sorting is cool and all, and may be somewhat of an indication of
	  system design worth, but all this attention is stretching its
	  utility, IMHO.
</ul>
<hr>
<a href="index.html"><i>Back to index</i></a>

</body></html>
@
