head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	97.04.10.15.35.24;	author gribble;	state Exp;
branches;
next	;


desc
@@


1.1
log
@parallel db systems
@
text
@<html>
<title>
Parallel Database Systems
</title>
<body>
<a href="index.html"><i>Back to index</i></a>
<h1>
Parallel Database Systems: The Future of High Performance Database Systems
</h1>
<strong>
David DeWitt and Jim Gray
</strong>

<p><b>One-line summary:</b>
The NOW argument applied to parallel database systems.
</p>

<h2>Overview/Main Points</h2>

<ul>
     <li> customized &quot;database machine&quot; hardware was a fad that
	  didn't work out - no economy of scale could be realized.
	  Similarly, high performance parallel systems (shared memory or
	  shared storage) didn't work out, partly for economic reasons and
	  partly because of the interference that sharing of resources
	  induced.
     <li> shared memory/shared disk:  data affinity introduced as
	  coarse-grained partitioning strategy - authors point out this is
	  first step towards shared-nothing model (i.e. essentially a NOW).
     <li> parallel metrics:
	  <ul>
	       <li> <B>speedup</b>:
		    small_system_elapsed_time / big_system_elapsed_time.  
		    throw more resources at problem, how much faster is
		    problem solved?
	       <li> <B>scaleup</b>:
		    small_system_elapsed_time_on_small_problem /
		    big_system_elapsed_time_on_big_problem.  Like TPC
		    benchmarks - difficulty of problem scales up with
		    amount of resources you throw at it.
	  </ul>
     <li> Shared-nothing architectures:  if done right, can achieve
	  near-perfect linear speedups and scaleups on complex relational
	  queries.
     <li> relational queries perfect for parallelization, as queries are
	  relational operators (at an abstract, non-procedural logical
	  level) applied to large collections of data.  Execute as dataflow
	  graph
	  <ul>
	       <li> &quot;pipelined parallelism&quot; (which is doing many
	  stages of a query in pipelined fashion), and
	       <li> &quot;partitioned
	  pipelined parallelism&quot; (which is doing many such pipelines
	  at once on different machines - partitioned either over operator
	  space or over data space).
	  </ul>
     <li> data partitioning - use hash, round-robin, or range partitioning.
     <li> some mention of state of the art in 1992 is mentioned - teradata,
	  tandem nonstop SQL, gamma, bubba, ... are mentioned.
</ul>

<h2>Relevance</h2>
The NOW argument applied to parallel databases.  Not distributed databases,
but parallel, so get sysadmin and LAN/SAN benefits.  Good argument, makes
sense for databases and other systems in general.


<h2>Flaws</h2>

<ul>
     <li> this paper seemed targetted at a non-tech audience;  more PR than
	  paper
     <li> paper is a number of assertions, with no backing up through data,
	  measurements, experiments, or historical evidence.
     <li> examined tech trends leading to state of the world in 1992 - how
	  about tech trends leading into the future?  Will this argument
	  still be true in 2000?
</ul>
<hr>
<a href="index.html"><i>Back to index</i></a>

</body></html>
@
