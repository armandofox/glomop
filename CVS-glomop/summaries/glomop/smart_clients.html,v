head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	96.12.15.21.34.58;	author fox;	state Exp;
branches;
next	;


desc
@@


1.1
log
@Fixed formats in multimedia summaries, added some GloMop summaries and the computers and society subdir
@
text
@<html>
<title>
Smart Clients (WebOS)
</title>
<body>
<a href=index.html><i>Back to index</i></a>
<h1>
Using Smart Clients to Build Scalable
Services
</h1>
<strong>
Chad Yoshikawa, Brent Chun, Paul Eastham, Amin Vahdat, Tom
Anderson, David Culler, UC Berkeley
</strong>

<p><b>One-line summary:</b>

Realize scalability through managed replication of servers, either
static or dynamic, along with service-specific client support code to
locate and talk to 
an appropriate replica, fail over when that replica goes down, etc. (as
opposed to "generic" support in servers for scalability)</p>

<h2>Overview/Main Points</h2>

<ul>
  <li> Philosophy/assumption: it is simpler to upgrade all clients than
       all servers, so we should leverage that in deciding where to put
       support for scalability.  
  <li> Services accessed by Smart Clients assumed to be provided by a
       (dynamic) set of peer servers; choice of which one should account
       for geography/network topology, load balancing, etc.
  <li> "Director" applet (servicelet?) is the single client-resident
       service interface: "Perform this action on some server node".
  <li> Director applet keeps its peer list for each service up-to-date
       via an application-specific mechanism.  
  <li> Bootstrap: modified <i>jfox</i> browser to support "service://"
       name space; services looked up at well-known search engines to
       get a <i>service certificate</i> which binds to the client
       interface and director applets and gives initial hint as to
       service group members; Director may contact one of the members to
       validate the list.
  <li> Existing applet examples: telnet front-end to NOW (load
       balancing, currently no failover); FTP mirror client; chat, using
       an append-only WebFS file, with multiple WebFS servers mirroring
       the file and multicasting updates every 300ms.  (But see below)
</ul>

<h2>Relevance</h2>

<h2>Flaws</h2>

<ul>
  <li> Seems like the mechanism for keeping server lists up to date
       should not necessarily be application-specific; should have at
       least some support for making it easier (e.g. choice of polling,
       multicast update, or lazy invalidation).  Because of this, the
       "fault tolerance" claim is suspect; how exactly is FT provided?
       It's application-specific.
  <li> Chat app: with all servers multicasting file updates every 300ms,
       is this really scalable?  There are no ordering semantics, except
       those you're likely to get from such frequent updates, though
       authors acknowledge that any well-known ordering scheme
       (e.g. ISIS) could be used.
  <li> Authors claim that "entrenched" URL naming scheme is difficult to
       modify so we should try to be compatible with it; yet they extend
       the naming scheme themselves to support other applications (chat,
       etc).
  <li> How easy is it, really, to upgrade clients? Assumes users are
       willing to install upgrades on demand, willing to run extra code
       in their client, and that client software is largely uniform. Not
       clear how long these conditions will persist.  Should be done in
       a proxy instead :)
</ul>

<ul>

</ul>
<hr>
<a href=index.html><i>Back to index</i></a>

</body></html>
@
