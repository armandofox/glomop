head     1.1;
branch   1.1.1;
access   ;
symbols  initial:1.1.1.1 initial:1.1.1;
locks    ; strict;
comment  @# @;


1.1
date     96.11.14.07.51.58;  author fox;  state Exp;
branches 1.1.1.1;
next     ;

1.1.1.1
date     96.11.14.07.51.58;  author fox;  state Exp;
branches ;
next     ;


desc
@@



1.1
log
@Initial revision
@
text
@<HTML>
<HEAD>
    <TITLE>Integrated Layer Processing</TITLE>
</HEAD>
<BODY>
<H1>Increasing Network Throughput by Integrating Protocol Layers</H1>
Mark B. Abbott and Larry L. Peterson, Univ. of Arizona 
<H2>One-line summary</H2>
Collapsing protocol layers to increase performance and reduce copying and
buffering is straightfoward in principle, but getting the implementation
right requires overcoming CPU-specific performance obstacles (cache performance,
register spilling, etc.), dealing with unusual protocol semantics (ordering/fragmenting,
etc.), and sacrificing some modularity which is difficult to restore.  The
benefit ultimately depends on the CPU-to-memory gap.
<H2>Main ideas</H2>
<UL>
  <LI>Main obstacles to overcome:
  <UL>
    <LI>Awkward data manipulation (non &quot;loop style&quot;)
    <LI>Different &quot;views&quot; of data (level N headers are part of
level N-1 data)
    <LI>Ordering/fragmenting constraints (updating connection state, etc.
in middle layers)
    <LI>Preserving modularity
  </UL>
  <LI>Previous work showed only marginal improvements from ILP, but that's
because it included DES encryption, so protocol was compute-bound rather
than memory or I/O bound, and because CPU cache effects were not considered
  <LI><B>Word filters:</B> operate on a machine word at a time conceptually;
can retain state to do multibyte/multistage operations.  &quot;Output&quot;
consists of passing word(s) to next filter.
  <LI>Word filters implemented as inline source macros to avoid function
call overhead and allow state across words to be maintained in registers
  <LI><B>Cache effects</B> dominate data-manipulation performance; wide
variety of experiments across machine types, transformation &quot;types&quot;,
and cache extremes (all hits and all misses)
  <LI>Benefits: eliminate loads/stores, reduce loop overhead, fewer load
delays slots therefore more likely to be filled, eliminates buffer management.
 (Armando's observation: also gives larger basic blocks which is good for
compilers; but loops have larger bodies.  Probably still too small to affect
I-cache behavior, which is dominated by OS anyway, but would have been nice
to see a reference.)
  <LI><B>Register pressure</B> is key constraint to &quot;scalability&quot;
of approach; performance knee corresponds to register spilling.  Ratio of
local variables to layers gives slope after knee.
  <LI><B>Performance prediction</B> model given which depends on loop overhead,
computation, and cache performance.
  <LI><B>Headers vs.data:</B> separate application message into new abstract
data type, <I>segregated message</I>.  Can only be done when application
data boundaries coincide with lower-level boundaries, which calls for application-level
framing in future protocols.
  <LI><B>Ordering constraints:</B> separate message delivery into initial,
manipulate, and final stages; manipulation stages can be collapsed.
  <LI><B>Throughput improvements</B> of 30-60% were observed in most cases.
 (Throughput is important metric since today's fast LANs have bandwidth
in excess of what the protocol stack can handle; ILP should reduce hardware/synchronization
overhead as well.)
  <LI><B>Preserving modularity: </B>prototype for automatic synthesis is
described, but it's very crude.
  <LI><B>Other barriers to integration</B> include data delivery that is
not &quot;streamlike&quot; (eg a protocol that deliberately destroys data
locality to enhance error resistance) and protocols for which the next &quot;decapsulation&quot;
is not known until the current layer processing completes (demuxing, generalized
routing, packet forwarding).
</UL>
<H2>Comments/Flaws</H2>
The title is misleading in that it belies a surprisingly detailed performance
analysis of the &quot;low-level&quot; (memory, CPU, etc) effects of ILP,
making this a good architecture/networking &quot;crossover&quot; paper.
<UL>
  <LI>&quot;PES&quot; (pseudo-encryption standard) example used to illustrate
&quot;nontrivial&quot; stateful word filters is in fact too simple to be
realistic.
  <LI>The single &quot;data access&quot; parameter to prediction model is
too simplistic, especially with today's sophisticated cache architectures.
  <LI>The idea of ILP is straightforward, but this paper shows that getting
the implementation right is difficult for nonobvious reasons; to that end,
there should be more graphs. 
</UL>
<H2><HR></H2>
<A HREF="index.html">Back to index</A> 
</BODY>
</HTML>
@


1.1.1.1
log
@
@
text
@@
