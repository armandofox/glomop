head     1.1;
branch   1.1.1;
access   ;
symbols  initial:1.1.1.1 initial:1.1.1;
locks    ; strict;
comment  @# @;


1.1
date     98.08.03.23.33.23;  author fox;  state Exp;
branches 1.1.1.1;
next     ;

1.1.1.1
date     98.08.03.23.33.23;  author fox;  state Exp;
branches ;
next     ;


desc
@@



1.1
log
@Initial revision
@
text
@<HTML>
<HEAD>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
   <META NAME="Author" CONTENT="Dogbert">
   <META NAME="GENERATOR" CONTENT="Mozilla/4.04 [en] (Win95; U) [Netscape]">
   <TITLE>GloMo PI Proxy Workshop Notes</TITLE>
</HEAD>
<BODY>

<H1>
Proxy Architecture Issues breakout session</H1>
DARPA GloMo PI meeting, Feb 23-25, Santa Cruz.&nbsp; These notes by <I><A HREF="mailto:fox@@cs.berkeley.edu">fox@@cs.berkeley.edu</A></I>
<H2>
Jerry Popek, Agents</H2>

<UL>
<LI>
Adaptive composable agents, nice failure semantics across multiple nodes</LI>

<LI>
Approach: standard runtime, env. monitoring, planning/deployment of "adapters",
semantic-based (content-based?) failure recovery</LI>

<LI>
Sometimes prefer hop-by-hop over end-to-end adaptation; multiple adaptations
can't be easily composed in an end-to-end-only system</LI>

<LI>
Many of same issues as ProActive: composability, "path discovery" (actually
called "multisite planning and deployment", which is slightly different),
failure semantics along the path, "paired operator" injection, etc. (Security??)</LI>

<LI>
Example issue for failure semantics: URL naming and stale links.&nbsp;
Soln: URL interposition ("adapters")</LI>

<LI>
Basic prototype built, example apps being constructed</LI>

<LI>
Goal: composability, and require this API in the "architecture" (whatever
that turns out to be)</LI>
</UL>

<H2>
Satya, disconnected operation and client API's</H2>

<UL>
<LI>
FS transparency to client <I>requires</I> client side stuff, can't be done
entirely in infrastructure.&nbsp; Adaptation is done by Venus.</LI>

<LI>
relies on Unix vnode interface.&nbsp; If kernel-to-app comm could be standardized
across platforms, would help in implementation of these types of systems.</LI>

<LI>
Since now dealing with updatable/writable data, failure semantics important:
clean failure modes highly desirable (Coda comes with RVM).&nbsp; <I>Armando
sez:</I> this is true for some apps and not others...fixed filesystems
often don't have clean semantics either</LI>

<LI>
Internal Interfaces: client->server, server->client (callbacks for consistency),
server->server (inter-server consistency).&nbsp; <I>Armando sez: </I>Why
not like Bayou, where everyone is a server?</LI>

<LI>
External (user visible) interface for adding conflict-resolvers: RESOLVE
files ("makefiles") per dir with resolution rules, which can be interactive.&nbsp;
<B>Atomicity of resolver actions guaranteed.</B></LI>

<LI>
ASR's are a security risk; essentially must trust Venus' "sandboxing" of
ASR's</LI>

<LI>
Conflict resolution: throw "file not found" for conflicted/unresolved files,
by doing symlinks to "magic" filenames which then get "exploded inplace"
by the user-level repair program, etc.&nbsp; <I>Armando sez:</I> it's weird
to force all this into the existing molds of filesystem semantics...besides
compatibility, what is the big win?&nbsp; (e.g. MS Outlook is "transparent"
too)&nbsp; <I>Satya replies: </I>Transparency is a double edged sword.&nbsp;
You'd still like Emacs to work on your laptop, right?</LI>
</UL>

<H2>
Badri, notification &amp; environment awareness</H2>

<UL>
<LI>
Apps subscribe to event channels ("multicast -like") and attach arbitrary
handlers to events.&nbsp; Architecture is object-oriented Java middleware.&nbsp;
(Separates policy from mechanism for event detection/generation.)</LI>

<LI>
Example channels: hardware (PC card insert/remove), power mgmt, network
conn, geographic location, user-defined...&nbsp; <I>Armando sez:</I> is
this namespace fixed, extensible, ....?&nbsp; the standard namespace questions.&nbsp;
<I>Badri sez: </I>there is a notion of a class hierarchy so you can respond
to more generic events if you don't understand the specific ones, etc.&nbsp;
Still some coding issues here but this seems like the right direction.</LI>
</UL>

<H2>
Julio Navas, geographic routing &amp; Geocasting</H2>

<UL>
<LI>
IP+GPS=geocasting</LI>

<LI>
<I>Route </I>a msg to a geographical area; <I>park</I> a message in an
area by storing it on a Geonode (server)</LI>

<LI>
Routers share geographic info obtained by GPS and construct a "routing
lookaside buffer" (my term) for forwarding; similar to multicast routing</LI>

<LI>
<I>Satya says:</I>&nbsp; (x,y) coords are just two metrics used for routing...could
use any two, correct?&nbsp; "Send this message to all hungry soldiers who
are running low on power".&nbsp; What is it about <I>physical</I> location
that simplifies this, and if nothing, why not solve the general problem?&nbsp;
<I>Jerry suggests:</I> it may be the triangle inequality, or some physical
property of distance in georouting that adds a constraint relative to having
arbitrary feature vectors.</LI>
</UL>

<H2>
Saurav, QoS &amp; proxies</H2>

<UL>
<LI>
Resource mgmt must be end-to-end (in the sense of "all levels of the stack")
and systemwide (in the sense of "across all running apps").</LI>

<LI>
QoS is everywhere.&nbsp; Have end-to-end "translators" (app QoS reqs to
"lower-level" reqs), allocating priorities to different apps,&nbsp; app
wrappers that enforce resource mgr decisions</LI>

<LI>
GloMo arch must have hooks at all levels for QoS. <I>Armando sez:</I>&nbsp;
But what do they look like?</LI>

<LI>
The n-dimensional "benefit function" has to capture all of the application's
"axes" of adaptation, and the system performs gradient-search and related
math techniques to tell each application along which axes to adapt.&nbsp;
<I>Armando sez:</I> capturing all this stuff (which we agree we don't understand
all that well) in a nice closed curve seems really hard.</LI>
</UL>

<H2>
Messages to DARPA/Rob Ruth</H2>

<UL>
<LI>
QoS is slippery and there's a fine line between it and app-specific customization,
etc.&nbsp; It is not the case that QoS is a nicely-circumscribable problem
which we have merely failed to solve so far.</LI>

<LI>
Transparency vs. app-specific mechanisms: If you do the app-specific way
(CVS, calendar manager, etc.), <I>everyone</I> has to use the same system.&nbsp;
This isn't a problem with FS-based stuff.&nbsp; <I>Armando sez:</I>&nbsp;
How about a hybrid?&nbsp; App-specific for people who have it, but fall
back to FS-based transparency for backward compatibility?&nbsp; <I>Jerry
sez:</I>&nbsp; Fine, but the interfaces should be orthogonal. <I>Armando
agrees.</I></LI>

<LI>
<I>Saurav sez:</I> Need global view of rsrc management.&nbsp; <I>Armando
responds:</I> unfortunately, the only time we seem to get that view is
at GloMo PI meetings and the like...we should be careful not to fall into
the trap where every piece relies on every other piece for anything at
all to work.</LI>

<LI>
Disconnected operation requires a lot more support on the client, but the
question of transparent vs. app-specific disconnection semantics is still
valid.</LI>
</UL>

<H2>
Pieces of an architecture</H2>

<UL>
<LI>
</LI>
</UL>

<H2>
Messages to Myself</H2>

<UL>
<LI>
Keep talking to Jerry about ProActive, TACC, and agent stuff....lots of
overlap there.</LI>
</UL>

</BODY>
</HTML>
@


1.1.1.1
log
@
@
text
@@
