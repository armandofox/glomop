head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	97.11.05.09.25.23;	author fox;	state Exp;
branches;
next	;


desc
@@


1.1
log
@*** empty log message ***
@
text
@<HTML>
<HEAD>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
   <META NAME="Author" CONTENT="Dogbert">
   <META NAME="GENERATOR" CONTENT="Mozilla/4.01 [en] (Win95; I) [Netscape]">
   <TITLE>Logging and Log Analysis</TITLE>
</HEAD>
<BODY>

<H1>
Logging and Log Analysis</H1>

<H3>
What's new &amp; different about logging?</H3>

<UL>
<LI>
International scope assumed</LI>

<LI>
Volume of traffic (hence data size) is Gbytes/day; storage, searching,
static analysis</LI>

<LI>
trend analysis (similar to online aggregation) typically more useful than
static analysis</LI>

<LI>
Email is rare (usually complaints); logging is your <I>only</I> form of
contact with users</LI>

<LI>
Precious/secret resource; hence literature is sparse</LI>
</UL>

<H3>
Why do it?</H3>

<UL>
<LI>
User feedback at detailed level, and content targeting per user; try <I>that</I>
with TV ads!</LI>

<LI>
<I>Revenue!</I>&nbsp; logs -> reports -> advertiser business -> $.&nbsp;
Do advertisers trust service providers to generate the reports?&nbsp; Yes
for HotBot, since Wired started it at a time when there was no reporting
mechanism, so&nbsp; it set the standard.&nbsp; Traditionally an outside
agency "validates" the logs/analysis/reports, or generates reports internally
from the raw logs.</LI>

<LI>
Advertisers care about:</LI>

<UL>
<LI>
&nbsp;# hits</LI>

<LI>
demographics of audience (simple ex.: .com vs .edu hits)</LI>

<LI>
contract verification: some ads supposed to be delivered only to certain
kinds of users</LI>

<LI>
<I>sell-through</I>: percentage of shown ads that you can charge for</LI>
</UL>

<LI>
Logs are large enough that log analysis is a data mining/online aggregation
problem.</LI>
</UL>

<H3>
Stuff You Can Do: Post-Mortem Analysis &amp; Virtual Focus Groups</H3>

<UL>
<LI>
Browser targeting: new features vs. compatibility</LI>

<LI>
Browser targeting: percentage of Netscape browsers is roughly indicative
of percentage of referrals coming from "Netscape Search" page.&nbsp; If
you're paying them to be on that page, you can estimate the current value
of that investment.</LI>

<LI>
Referral profile: number of hits from particular referer sites (Netscape
Search, Yahoo, etc.)</LI>

<LI>
Virtual focus group: double blind, on-line experiments that let you test
the effects of various changes on your user base, user loyalty/retention,
user behavior, etc.</LI>
</UL>

<H3>
How do you deal with all this data?</H3>

<UL>
<LI>
Random/uniform sampling (doesn't work for rare events or one-time artifacts
like UI changes)</LI>

<LI>
Build tables or aggregates of interesting stats as you go; discard data
as you go.&nbsp; Problem: anything you forgot to aggregate, you're stuck.</LI>

<LI>
Store everything (gzip gives you 5-6x) on disk or tape</LI>

<LI>
In practice: do everyting you can think of a priori; sample to answer other
questions when you can</LI>

<LI>
What about people who have more than one user id (because they use service
from more than one computer, or whatever)? Stats are biased towards those
users.</LI>

<LI>
Statistical process control: check each component of the process by doing
random sampling to ensure it's inside some "normal" operating range.&nbsp;
HP does this for printer parts, with the result that their printers tend
to work the first time you turn them on <I>even though they've never been
tested as a system.</I></LI>

<LI>
<I></I></LI>
</UL>

<HR WIDTH="100%">
<ADDRESS>
fox@@cs.berkeley.edu, brewer@@cs.berkeley.edu</ADDRESS>

</BODY>
</HTML>
@
