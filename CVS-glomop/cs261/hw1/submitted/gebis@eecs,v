head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	98.10.02.18.32.12;	author daw;	state Exp;
branches;
next	;


desc
@@


1.1
log
@*** empty log message ***
@
text
@From gebis@@cory.EECS.Berkeley.EDU  Fri Oct  2 02:03:39 1998
Return-Path: gebis@@cory.EECS.Berkeley.EDU
Received: from po.EECS.Berkeley.EDU (po.EECS.Berkeley.EDU [128.32.134.172]) by joseph.cs.berkeley.edu (8.8.5/local) with ESMTP id CAA09063 for <cs261-homeworks@@joseph.cs.berkeley.edu>; Fri, 2 Oct 1998 02:03:39 -0700
Received: (from gebis@@localhost)
	by po.EECS.Berkeley.EDU (8.8.8/8.8.8) id CAA18773
	for cs261-homeworks@@joseph.cs.berkeley.edu; Fri, 2 Oct 1998 02:00:34 -0700 (PDT)
Message-Id: <199810020900.CAA18773@@po.EECS.Berkeley.EDU>
Subject: CS261 HW1
To: cs261-homeworks@@joseph.cs.berkeley.edu
Date: Fri, 2 Oct 1998 02:00:34 -0700 (PDT)
From: "Joseph Gebis" <gebis@@eecs.berkeley.edu>
X-Mailer: ELM [version 2.5 PL0b2]
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
Status: RO

> Joseph Gebis
> CS261 HW1
> 
> I know that the HW said to be brief, but I also wanted to be complete.
> If this is way too non-brief, just let me know and in the future
> I'll keep my answers shorter.
> 
> 1)
> a) ftpd/gnutar
> 
> The basic problem here is one of unnecesarry functionality (or
> complexity) creating unexpected interactions.  The first principle
> to consider is economy of mechanism, applied in two different
> ways: first, to tar; secondly, to ftpd itself.
> 
> The obvious cause of the problem is the extra features in gnutar.
> Are these features necesarry?  Possibly, to someone, somewhere.
> Are they necesarry to simply package files together?  Absolutely
> not.  The first application of economy of mechanism, then, 
> suggests that when we decide to allow access to a program with
> a specific purpose in mind (packaging files together), we
> allow access to a program that does only that.  A simple way
> to do this would be to use a simple tar program that does
> not have extra features we don't need.
> 
> The second application of economy of mechanism goes to ftpd.
> Does ftpd need to be able to support execution of external
> programs such as tar?  Again, this could potentially be
> useful, but it opens up just that many more places that security
> flaws can be found.  If security is important, perhaps ftpd
> should not allow execution of external programs.
> 
> Another useful principle is that of least privilege.  The
> ftpd/gnutar interaction allows a command to be run as ftp;
> perhaps the unix security model gets in our way somewhat, but
> if ftp really had the least privileges it needed (that is,
> access to as few things that it needed), perhaps being
> able to run a command as ftp would not gain an attacker anything.
> 
> b) sendmail alias expansion/program execution holes
> 
> Is sendmail the perfect example of a system that does not employ
> economy of mechanism, or what?  The legacy formats that it accepts
> cause it to be extremely complex, and therefore difficult to
> examine for problems exactly like this.  A simpler sendmail would
> definitely be easier to examine for problems.
> 
> Another design methodology that would perhaps have solved problems
> of this type is to group like actions; if all address expansions
> were handled in one location (and the code was written so that
> it would be very difficult to expand addresses in other places, so
> that this single point wouldn't be easily be accidently subverted
> in the future), the checks could have been done there, once.
> 
> It would also be nice to be able to run sendmail sandboxed in
> the mail system; that way, even if there were problems in
> sendmail, the entire system would not be compromised.
> 
> c) mediation in java
> 
> The problem of missing an access control check could be fixed if
> access to objects were somehow implemented with fail-safe defaults;
> that is, it a missed check would cause access to NOT be granted
> to anyone, rather than a missed check causing access to be
> granted to everyone.  
> 
> d) tractorbeaming in wuftpd
> 
> One way to partially mitigate this sort of problem is to have
> two different ftpds (or one that really acts like two): one for
> non-anon users (that does have to seteuid(0) sometimes), and
> one for anon users (that does not).  This limits the problem
> somewhat, but doesn't prevent the same attack from being used
> by non-anon users.
> 
> Another possible way to deal with this is to have the initial
> ftpd just spawn a sandboxed ftpd inside the user's home directory.
> Although this limits functionality (it's no longer possible to
> access some files directly), it also limits the damage that can
> be caused.
> 
> 2) covert java channels
> 
> The most obvious channel is the network connection back to the
> originating host, but this hardly seems "covert".
> 
> Another possibility is that running a tight loop of code could
> cause the system to become more busy, and therefore take longer
> to respond to some unrelated network probe activity (finger? ping?).
> 
> Large chunks of memory could be consumed, causing increased swapping
> activity, which would again causes system activity that would
> be reflected in longer response times.
> 
> I believe that applets can go back to the original host when
> additional classes are required.  A very limited covert channel
> can be created by using specific classes in a certain pattern.
> 
> If we assume the model is that the java applet is malicious, but
> the originating host is not (for example, an evil cracker somehow
> tricked another host to place the applet on their page; or was
> able to overwrite an existing applet because of an ftp bug, or
> something), a covert channel can exist anyway: the applet can
> send large amounts of information back to the originating host.
> While this is basically a modification of the timing channels
> above, it might be easier to exploit off of the originating host;
> for example, if it has a low-bandwidth connection, it might be
> easier to flood to a detectable level.
> 
> 3) 
> All of the following assume that the attacker has access to
> the tcp stream somehow.
> 
> With no additional crypto: insert a completely bogus packet with
> the right sequence number (will bong the connection, but who cares?);
> replace packets from the client with same-sized packets containing
> what you want (will ruin part of the communications, but keep the
> connection ok); desynchronize the connection, insert as you please (will
> not hurt the connection, except for the massive acks).
> 
> The following two assume that keys are exchanged securely (if they
> aren't, then just look at the keys and insert as above).
> 
> With Triple-DES ECB mode: if the data alone is encrypted, then
> the same inputs lead to the same ciphertext.  If the session is
> interactive, then many (most?) of the packets from the user
> will consist of a single letter.  Possibly by doing some sort
> of traffic analysis and frequency estimation (or if one knew what
> the client was typing by some other means), one could guess what
> was the encrypted packet of "e", "c", "h", and so on.
> 
> With Triple-DES CBC mode: At this point, we're assuming:
> 1) strong authentication
> 2) strong cipher
> which means that pretty much any sort of direct attack won't work.
> One possibility is to insert yourself in the middle of the whole
> pipe: if host A is trying to get to B, and the attacker M has control
> of all the traffic between A and B (playing any of the routing games),
> M can set up a secure link to B (at which time it gets presented with
> the authentication challenge); then respond to A as B (issuing the same
> challenge); then shuffle data across (with the first data being A's
> response to B's challenge).  Insert at will.
> 
> How to fix these weaknesses?  Well, the weaknesses in any of the
> first two are fixed by going to a better cipher.  The weaknesses
> in the last one are solved by doing some sort of public key
> authentication (but this begs the question of how to initially
> establish identity).
> 
> 4)
> The obvious weakness is that these negative responses can be forged.
> If a faked negative response is sent in response to a dns query and
> arrives faster than the real response (or the real response
> dropped, etc), a denial of service attack occurs.
> 
> To allow negative responses to be authenticated, simply accept only
> signed negative responses from someone that should know (eg, 
> berkeley.edu saying "nonexistant.berkeley.edu doesn't exist", or
> dot saying "nodomain doesn't exist").  As long as we guarantee
> that negative responses can't enter our caches any other way (say,
> tacked onto other valid responses), we can simply put the information
> in the cache.  This way, we 1) authenticate valid negative responses,
> and 2) don't accept any non-authenticated negative responses.

@
