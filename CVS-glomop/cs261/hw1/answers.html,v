head	1.2;
access;
symbols;
locks; strict;
comment	@# @;


1.2
date	98.10.10.00.17.47;	author daw;	state Exp;
branches;
next	1.1;

1.1
date	98.10.08.08.43.37;	author daw;	state Exp;
branches;
next	;


desc
@@


1.2
log
@*** empty log message ***
@
text
@<html><head><title>Answers to homework #1</title></head>
<body bgcolor="white">
<h1 align="center">Answers to homework #1</h1>
<p>Here are some suggested solutions to the first homework.</p>

<p>Note that the homework you handed in should have been much
shorter than this page.
There are two important reasons why this page is so long:
<nl>
<li>In many cases, we have listed several possible answers for each
	question; but you only needed to give one answer.
<li>For clarity, we have described the answer in greater detail
	than necessary; you could have just sketched the main idea.
</nl>

<h2>Question 1</h2>

<p>1. ftpd/gnutar
<ul>
<li>Not so great: Turn off the tar feature.
<li>Good: Sandbox it.
<li>Good: Give tar only limited capabilities (e.g. disallow network access).
<li>Better: Write your own minimal version of tar
      (either as a separate process or integrated into ftpd).
<li>Better: Only allow a limited known-safe subset of tar command-line arguments.
</ul>

<p>2. sendmail
<ul>
<li>Ok, but not so great: Sandbox it.
<li>Better: Keep state about where you got the alias from
      (whether from a trusted local config file, or from a remote site);
      use this context to check program executions.
<li>Also good: Specify programs in a different config file from
      aliases, rather than overloading the meaning of e-mail
      addresses and /etc/aliases.
      This way the administrator is forced to explicitly
      allow each program he wants to execute in a "programs.allowed.cf"
      config file, and this should be more robust.
</ul>

<p>3. Java
<p>(By the way, there's probably a workable CS261 project in the
answers to this question...)</p>
<ul>
<li>Ok: Sandbox it.
<li>Better: Fail-safe defaults (deny all accesses which haven't been
      checked by the SecurityManager).
<li>Excellent: All security-critical native methods (e.g. mkdir) are
      called directly from within the SecurityManager class which does the
      access checks (and not otherwise exported to the world);
      this way you can't forget to check any important calls.
<li>Excellent: Have all library calls be vectored to a single monolithic
      entity which does access checks.
<li>Excellent: Don't load the class for e.g. network access if
      the applet isn't supposed to have that access.
</ul>

<p>4. tractorbeaming
<ul>
<li>Not so great: Separate into anonymous and non-anonymous ftp.<br>
    This is not great because the non-anon ftpd will still be vulnerable;
    and also because it still might allow for other race conditions
    (remember, the point was to find a general fix which would prevent
    any other vulnerabilities of this class from happening in the future).
<li>Good: Security-critical sections should be atomic.
<li>Good: Temporarily drop privileges in signal handlers.
<li>Excellent: Permanently revoke all privilege after starting execution.
</ul>



<h2>Question 2:</h2>

<p>To get a good mark, you describe more than one of the following.
(This question called for brainstorming...)</p>
<ul>
<li>Standard: Send the data directly (not very covert, but hey...).
<li>Not so good:
  Send it in a gif, hidden with steganography
  (clients don't usually upload pictures to servers, so this would
  probably stand out if anyone thought to look for it).
<li>Good: Disguise as an email connection.
<li>Good: Vary timing rate of packets sent to originator.
<li>Good: Spin-loop to control CPU load;
  then the colluder measures response time
      with pings, fingers, or whatever back to the machine running the applet.
<li>Good: Encode information in URL requests back to originator.
<li>Good: Upload information in a form.
<li>Good: Vary port numbers of connections to communication information.
<li>Great: Observe that some of these can be modified to leak
      the secret information to a colluder
      by bouncing off the originator,
      even if the originating web server is not in collusion with the attacker
      (e.g. ftp port bounce, mail relay, URLs if originator will serve
      as a http proxy, etc.).
<li>Brilliant: Hide information in outgoing DNS queries
	(e.g. www.byte-117-is-0x5A.covert.hackers.org).
<li>Brilliant: Encode information in which additional Java classes are
	requested from originator (because Java uses dynamic linking).
</ul>




<h2>Question 3:</h2>
<p>A common fallacy: This question is not about confidentiality; it is
   not about attempts to recover what the user typed (unless that
   is useful in defeating the integrity protection).
   This question is about protection against modification
   (i.e. integrity protection, or equivalently
   message authentication).</p>

<p>1. No encryption
<ul>
<li>Fine: TCP hijacking; or routing attacks;
or compromise a router and modify packets that traverse it.
</ul>
<p>2. ECB mode
<ul>
<li>A common fallacy:
   Note that while you can recover the plaintext->ciphertext mapping
   in part 2, you can't learn the key.
<li>Right: Learn parts of the codebook, and do replays.
   (You can often learn a fair amount of the plaintext->ciphertext
   mapping, since typing is slow and each keystroke is often in its
   own packet; frequency analysis helps.
   Then you can piece together a list of ciphertexts which
   correspond to "echo + + > ~/.rhosts", and insert them into the
   TCP stream via hijacking.)
</ul>
<p>3. CBC mode
<ul>
<li>Wrong: ``Try all keys.''<br>
   There are 2^168 Triple-DES keys; this is an astronomically large number,
   and certainly too large to search.
<li>Pretty good: Poor man's version: If a new IV is sent in each packet, you
   can flip bits in the first block of plaintext in any packet
   by flipping the corresponding bits of the IV (and leaving the
   rest of the ciphertext unchanged).
<li>Almost: If each separate packet has a new IV, you can append
   a ciphertext block to the end of a packet; the issue is whether
   you can set things up so that the appended ciphertext block
   will decrypt to something useful, and it looks like this might
   be hard to do with only at most 8 bytes.<br>
   <em>But</em> if you append a segment of consecutive ciphertext blocks
   from a previous connection, then you can make the attack work
   and replay previously-typed commands.  This starts to look like
   the splicing attack; see the next item.
<li>Excellent: The TCP splicing attack in Bellovin's paper
   <a href="http://www.research.att.com/~smb/papers/badesp.ps">Problem
   areas for the IP security protocols</a>.
   [ We'll explain more details in class about how this works. ]
</ul>
<p>4. The right way to fix these weaknesses
<ul>
<li>Ok, but not great: Each packet should include a public-key signature
   of its contents.<br>
   Note that public-key digital signatures are relatively slow, so a MAC
   is typically better for performance reasons.  MACs are typically
   as fast or faster than symmetric-key encryption.
<li>Great: Authenticate each packet with a MAC.
<li>Semi-good: It's also somewhat useful to change session keys frequently:
   change keys for every new connection (or even more often),
   and use a different key for each direction.
<li>Wrong!  ``Use a simple checksum.''<br>
   Note that using a non-cryptographic checksum (e.g. a CRC) is
   NOT enough -- you need a keyed cryptographic checksum, i.e. a MAC.
   Even an unkeyed cryptographic checksum or a cryptographic hash
   (like e.g. SHA-1) is not sufficient.
<li>Wrong!  ``Use a stream cipher.''<br>
   Note that stream ciphers are even worse.  They do prevent replays,
   but make it really easy to modify the plaintext -- you can flip
   bits in the plaintext by flipping the corresponding bits in the ciphertext.
</ul>



<h2>Question 4:</h2>

<p>1. Weaknesses?
<ul>
<li>Standard: Denial of service is possible.
<li>Great: With fake negative responses, clients might be tempted to
   fall back to insecure mechanisms.  For instance, in the case of
   e.g. rlogind and similar services, .rhosts can be rendered useless
   and the user can be forced to fall back to typing a (sniffable) password.
   As another example, clients might be tempted to fall back to insecure
   DNS when a secure DNS lookup fails (you can imagine this might be a
   very common policy for the several years it takes for all Internet
   nameservers to change over to using secure DNS).
<li>Good: Upon getting a negative answer from one DNS server,
   clients may be forced to approach a second DNS server, which may attacks
   easier for the adversary since the second server may be on a more
   vulnerable path or may have been compromised.
<li>Good: What do you do if you get a negative response claiming
   .com doesn't exist?  Well, one answer is that everything under .com
   falls off the Known Net.  But that's pretty bad.  Another response might
   be to imagine that clients will do some simple fallback, and trust
   all subdomains of com via some insecure mechanism (e.g. unauthenticated
   DNS), since we don't know what the public key is for .com.
   But in this case attacks would be possible, because then you can send
   a fake DNS record for microsoft.com.
   This one is probably pretty hard to pull off, and requires a lot
   of assumptions on the clients, but it's a good observation
   about a potential pitfall.
<li>Good: It might be really hard to obtain a trusted authentication path,
   since the whole scheme requires a method for every host to prove to
   its authoritative DNS server who it is and that its name->address
   lookup is valid.  This is a big policy issue.  For instance, having
   everyone show up physically and present photo ID to a sysadmin has
   problems: it doesn't scale so well.  So this is really a trust issue;
   if we're using cryptography, we might get a false sense of security,
   and forget to check the trust issues.
<li>Excellent: Search path hackery.<br>
   Suppose you have
   cs.berkeley.edu in your search path in /etc/resolv.conf.
   Now if you try to access www.ai (the Artificial Intelligence
   group's webserver), the hacker might inject a fake negative
   record for www.ai.cs.berkeley.edu; then you will be incorrectly
   directed to www.ai, a site in Anguilla.  In collusion with
   someone in Anguilla (which is probably not too expensive),
   hackers can cause serious havoc.<br>
   As another example, suppose you have
   <pre>
   cs.berkeley.edu
   eecs.berkeley.edu
   berkeley.edu
   hip.berkeley.edu
   </pre>
   in your /etc/resolv.conf.
   Now if you type "rlogin cory", the adversary can inject a fake
   negative record for cory.eecs.berkeley.edu, and you will be
   redirected to cory.hip.berkeley.edu.  (Note that cory.hip.berkeley.edu
   does in fact exist today!)
   Similarly, if someone types "microsoft/index.html" into their
   web browser, an adversary can make the DNS lookup for microsoft.com
   fail, and then the browser will try microsoft.cs.berkeley.edu
   and so on, which may allow for attacks.
</ul>

<p>2. Implementing authenticated negative responses
<ul>
<li>Minimal, but not great: Have local DNS server sign negative responses,
   or somehow set up an authenticated connection to your local DNS server.<br>
   The problem is that you can't necessarily hand off this negative
   record to anyone else and convince them of the authenticity of
   the negative record.
   This is because negative responses aren't self-authenticating:
   once you've obtained a negative response, you can't convince
   a third party that the host doesn't exist, unless the third party
   already trusts you.
   You really want to have the authoritative DNS server for the
   relevant zone sign the negative response with a public-key signature,
   so that you achieve end-to-end authentication.
   Otherwise, you end up with something analogous to per-link
   authentication, and if your local DNS server (or any other DNS
   server on the path to the authoritative DNS server) is compromised
   or confused, you can get the wrong answer.
<li>Slightly better, but still not great: Set up an authenticated
   connection to the authoritative DNS server.<br>
   Still not great, because the records still aren't self-authenticating.
<li>Standard answer: Have the authorative DNS server sign the
    negative response.  This way intermediate DNS caches/servers can
    present cached negative responses to clients who query them;
    this lets you aggregate caching across many clients, while
    minimizing trust in intermediate DNS servers.<br>
    One point some people missed:
    If there's a query for foo.bar.cs.berkeley.edu,
    and bar.cs.berkeley.edu doesn't exist,
    then cs.berkeley.edu should sign a negative record for bar.cs.berkeley.edu.
    (There's no chance that foo.bar.cs.berkeley.edu will
    exist but bar.cs.berkeley.edu won't.)
<li>A random nice observation: You should make sure to include a TTL
    (time-to-live) field in the negative response.
    Note that currently DNS already includes TTL's in negative
    responses, so all you have to do is sign the existing record.
    Better is to use absolute time (e.g.
    "expires 11:00am Oct 12th 1998") rather than relative time
    (e.g. "expires in 3 hours"), so that a DNS cache can present a cached
    negative response to clients or other caches.
<li>Excellent: A scheme to avoid the need for online signing.<br>
    One serious shortcoming of the previous schemes is that they all
    require DNS servers to sign negative
    responses in real time.  Online signing has serious disadvantages:
    there's a big performance hit (servers have to do a public-key signature for
    each negative response they generate), and more subtly there are
    security issues
    (because if the server's private key has to be online, that private
    key will be more vulnerable to compromise).<br>
    Here's a technique which allows authoritative servers to pre-compute
    negative response records offline,
    so they don't need to keep their private key online,
    and so that the performance of negative responses as good as possible.
    Suppose you are the authoritative server for cs.berkeley.edu.
    You sort the list of existing hosts in your zone
    (abacab, accidental, alakazam, ...), and number them as 
    host H[1], H[2], H[3], etc.
    The DNS record for host H[j] includes the name of H[j-1] and H[j+1],
    and you sign each record in an offline pre-computation;
    essentially, this is implementing a signed doubly-linked list.<br>
    Now if a client does a DNS lookup on abednego.cs.berkeley.edu, the
    server can return the signed records for abacab and accidental.
    This allows the client to check that there is no host whose name
    would fall in between abacab and accidental.<br>
    This is roughly what the IETF DNSSEC standard specifies today.
</ul>

</body></html>
@


1.1
log
@*** empty log message ***
@
text
@d4 12
@
