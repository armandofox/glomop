head	1.1;
access;
symbols;
locks; strict;
comment	@# @;


1.1
date	98.10.31.02.12.53;	author daw;	state Exp;
branches;
next	;


desc
@@


1.1
log
@*** empty log message ***
@
text
@From czerwin@@batman.CS.Berkeley.EDU  Fri Oct 30 15:49:27 1998
Return-Path: czerwin@@batman.CS.Berkeley.EDU
Received: from batman.CS.Berkeley.EDU (batman.cs.Berkeley.EDU [128.32.33.57]) by joseph.cs.berkeley.edu (8.8.5/local) with ESMTP id PAA14108 for <cs261-homeworks@@joseph.cs.berkeley.edu>; Fri, 30 Oct 1998 15:49:27 -0800
Received: from batman.CS.Berkeley.EDU (localhost [127.0.0.1])
	by batman.CS.Berkeley.EDU (8.9.1/8.9.1) with ESMTP id PAA03554
	for <cs261-homeworks@@joseph.cs.berkeley.edu>; Fri, 30 Oct 1998 15:48:34 -0800
Message-Id: <199810302348.PAA03554@@batman.CS.Berkeley.EDU>
To: cs261-homeworks@@joseph.cs.berkeley.edu
Subject: HW 2
Date: Fri, 30 Oct 1998 15:48:34 -0800
From: "Steven E. Czerwinski" <czerwin@@CS.Berkeley.EDU>
Status: RO


                                                        Steven Czerwinski
                                                        CS261 PS #2
                                                        October 29, 1998


Problem 1:  A Stateful Packet Inspection Firewall

Part 1: Compared to Application-Level Proxies

The main similarity between stateful packet firewalls and application-level
proxies is that they are both services that interpose themselves between
the outside world and the local "protected" network.  In both cases, this
interposition means that the services examine each piece of data coming in
from the outside world, and is able to decide whether or not it is safe to
pass on to the protected network.  Furthermore, both services are designed
to work for specific applications, like ftp or telnet.  They listen on 
specific ports that provide the functionality for that application, and 
decideds whether or not the incoming traffic is safe to pass on to the real
ports on the inside machine (they use application specific rules to determine
safety.)  Note, this means inside traffic is not monitored by both these
services.

The main difference between the two is that stateful packet firewalls
can only make security decisions based on the single incoming packet it
is examining, and the small amount of state it keeps.  As you pointed out,
this means that the firewall might not even have a TCP/IP stack; hence,
it is not looking at the whole incoming stream - just a packet of it.
It has to do this inorder to work as a packet filter.  If it did try to
keep a TCP/IP stack for all incoming traffic, it could become too burden.
This is different from the application level proxy which does keep track
of the entire stream, so that it sees the same sequence of information that
might end up being passed onto the inside host.  This has some fundamental
implications on what kind of protection each can offer.

Pros/Cons: There are some pro's for a stateful packet firewall over
proxies, but I am not quite sure if makes up for the disadvantages.
One pro is that the firewall is implemented in a small set of well-defined
rules, much like traditional packet filters.  This makes verification of
the security implementation much easier.  Application-level proxies are
probably huge, much more difficult to check over.  

Another pro that I like about stateful firewalls is that it is implemented
in a different logic form than the application itself.  By this I mean
that since the firewall must be implemented in these weird packet filter
rules, the firewall's design and ruleset is much different from the 
application's design and code.  An application level proxy might use the
same strategy that the application use to test security -- maybe even reusing
some of its source code.  Firewalls force us to think differently in order
to verify the safety of the incoming traffic, which I think will help since
designing the firewall might allow us to escape whatever logic flaws were
in the original application.

Another pro is that the firewall does do a better job at looking at the
lower level network messages, so it might be able to protect against
weird TCP/IP level attacks, that an application level proxy might not.

Ok, now for the con's.  The first con is that the firewall can only
affect security at the network level: it can only punch holes in the
firewall for communication streams, and remove those holes.
Application level proxies can provide a much finer level of security.
They can monitor the content of the streams, and block illegal
sequences.  For example, an ftp proxy might be able to detect when an
outside client tries to log in as root or access a sensitive file.  A
firewall can't (or shouldn't) really do this since this is merely
examining the content of the packets.  These sequences might be spread
across multiple packets, which would mean the firewall would have to
keep track of all recent packets, and try to reconstruct the entire
sequence.  This is too much work, and would amount to an application-level
proxy.

Another con of the firewall looking at the content is that there is
no way the firewall can do it effectively.  As stated before, firewalls
cannot keep track of the entire sequence of packets to reconstruct the
content of streams.  Therefore, if a firewall is looking at content to
detect security intrusions, it cannot do it perfectly, and therefore
attackers can get around it by simply spreading out their attacks across
as many packets as needed.  Of course, some protocols do just send single
packets back and forth (UDP), but these are probably not the most interesting
ones to examine.  

Basically, the level of security cannot be as fine as with a proxy.
We get the benefits of a smaller rule set and ease of verification, but
we can't do much with the security itself.  How many protocols
will really benefit from the ability to punch and fill in holes in
the firewall at will? Ftp does, but it was one of the few ones, and it was
even modified so that it could work with traditional firewalls. 
Application proxies can do much more by examining the content much more
fully.  They may be more complex and slower, but they can do much more
useful stuff.


Part 2: Compared to Intrusion detection services

There aren't too many similarities between these two.  They both
attempt to provide some level of assurance that the traffic from the
outside network isn't doing bad things to the local network computers.
They both employ knowledge about application behaviours and employ
rule sets in order to accomplish.  They both also use a relatively
small rule set, making design and verification easier.

However, they do differ in many ways.  IDs don't actively accept or deny
every piece of traffic like a firewall.  Also, IDs rely on trying to
reconstruct the entire incoming streams, whereas firewalls simply examine
each packet as it comes in.   They both do keep state on the incoming
network connections in this way, but the IDs state is much more complete.
Another big difference is that IDs work on examining both traffic originating
from outside and inside of the protected area.  Firewalls merely examine
traffic coming in from the outside.

Pros/Cons: What are the pros/cons of replacing an intrusion detection
system with a stateful firewall?  Well, one pro is that we are now
taking a much more active role the security mechanism.  We decide whether
or not a packet is safe before we pass it on.  IDS's only detect 
suspicious traffic, and warns the sys admin about it.  The damage could
already be done.

Another pro is that IDS can be flooded, and fall behind the network
traffic, and therefore miss some of traffic that is passed on.  This
cannot happen in a firewall since if a firewall falls behind, it drops
the packets.

One con in replacing the IDS is that the firewall no longer monitors
traffic originating from within the protected network.  The IDS used
to be able to detect if an insider was trying to do bad things to a
computer on the protected network, but since the firewall only mediates
traffic from the outside, this ability was lost.

Another con is that stateful firewalls cannot give the same fine level
of protection as IDS.  As mentioned in the Part 1, the stateful firewalls
cannot use complex rules examining all of the content of the incoming packets.
Instead, it uses very simple rules based on the current packet.  The IDS,
by being able to track the stream of traffic coming in, was able to
perform very complex/application specific checks on the content.  We lose
this ability with stateful firewalls, since these complex rules might be
the most interesting and useful things to monitor.


Problem 2:  An Upward Growing Stack

Making the stack grow upwards helps a little in preventing buffer overflow
attacks, but a determined attacker can see take advantage of these types
of attacks.

By making the stack grow upward, stack based overflow errors no longer have
access to the "previous" section of the stack.  By "previous" I mean the
portion of the stack the represents variables and return addresses of the
procedures that called the one in which the buffer was allocated.  This is
because these things were placed below the buffer on the stack (since we
are growing upward in memory).  And because of how stacks work, when
they overflow, they overflow upward.  Therefore, they overflow into areas
of the stack that represent other variables from the same procedure
in which the buffer was allocated, and variables and return values for any
procedure that the buffer procedure has called.  

Ok, so this does make our attacks more difficult.  A typical stack smashing
attach consists of overflowing the buffer so that it overwrites the return
value of the buffer procedure (procedure which allocates the buffer).  
This return value is always on the stack, since a procedure always has to
call the buffer procedure.  So, this attack can be mounted any time there
is a chance of overflowing the buffer.  However, we can no longer access
the return value of the calling procedure, since it is below the buffer on
the stack.  So, what can we do?  Well, we need to modify some return value..

So, we have to modify the return values of the procedures the buffer 
procedure calls.  Here's the basic sequence:  call buffer procedure.  It
allocates a buffer on the stack.  Call another procedure that will overflow
the buffer for us.  Since the stack grows upward, the return address of
the buffer procedure will be placed on the stack above the buffer (and 
therefore susceptible to overflows).  In that called procedure, hopefully
we can get it to overflow the buffer, and thus (by careful preparation)
overwrite the return value.  Now, when the called procedure tries to return,
it will jump to wherever we told it to.

This sequence, of course, relies on more factors going in our favor in
order for us to mount the attack.  Not only do we have to have a buffer
overflow error present in the code, but it must also occur in a procedure
that is called by the one in which the buffer was allocated.  Traditional
attacks only have to rely on there being a buffer overflow error present
in the code.  Therefore, a upward growing stack makes these attacks slightly
less likely.  But, we should take into consideration this:  a lot of 
buffer overflow mistakes are in lower level procedures that programs call to
copy stuff to the buffer, such as strcpy.  These procedures are called from
the buffer procedure, so do fulfill both requirements needed for the attack.
Therefore, with calls like strcpy, we can still mount them.

Ok, now for just quick run down on the attacks mention in the assignment.
I should first point out that any heap oriented overflow attacks can still
work the same way as before.  For instance, if there is a security critical
piece of code allocated on the heap, and if you have a buffer nearby it
in the heap you can overflow, then a upward growing stack does not affect
your ability to change that code.  

Ok, but if the security critical piece of data is on the stack, then you
can only overwrite it if the critical piece was allocated after the buffer
on the stack, such as when the buffer procedure calls a procedure that 
allocates the critical piece.  Plus, we can overflow the buffer after the
critical piece is put onto the stack, so this depends on the structure of
the code.  This is not as likely to happen, but still could in some cases,
so we are susceptible to it.

Stack smashing still works, but is a little less likely, as pointed out 
earlier.  We have to get it to overflow buffers in procedures that are 
called from the one in which the buffer was allocated.  This isn't that
uncommon, since strcpy could do this for us.  But, it does depend on the
code, and therefore we can only exploit it if the code is structured just 
right.

All the variants will work to.  We can put code in environment variables,
in data sections, point to another libc call.  The only challenge we have
is changing the return value to something we specify, which we can do as
pointed out earlier.

Overwriting a function pointer can only occur when that function pointer
was allocated in a procedure called from the buffer procedure.  Plus,
we can only overflow the buffer after the pointer was placed on the stack.
This is the sequence:  buffer procedure allocates buffer, calls function a,
function a places pointer on stack, function a calls b, b overflows the
buffer.  This sequence is a less lot likely to happen, so this attack
is not as worrisome, though it can happen.

Other attacks that are possible?  Well, there is a new attack of filling
in uninitialized variables on the stack.  Say the buffer procedure allocates
the buffer, and then calls procedure A.  Procedure A allocates space for 
some critical variables, and then does not initialize them, instead just
using whatever was on the stack.  This is a semi-common error to make.  
Well, before we call procedure A, if we can get a buffer overflow, we
can put whatever data we want in the place where the variables will be
allocated.  This is because our overflows are access areas in which future
variables will be placed.  This does not only work for procedures that
are directly called from the buffer procedure, but also for any procedure
that is called in turn.  Of course, this attack is only useful if modifying 
that uninitialized variables leads to interested behaviour.  It's harder
for us to control what will happen.  

Another attack that is now more critical is buffer underflows.  Of course,
buffer underflows rarely ever happen --- it's just how programmer normally
work.. you don't pass negative indices to a buffer (an underflow).  
But, if they were to happen, they are more critical now since underflows
access the same areas that the old downward growing stack overflows did.
Therefore, they could modify return values of the procedure that called
them and so on.
 
Problem 3:  Brain Barf

What can C compilers do to prevent overflow errors?  Let's start with some
simpler ones and work our way up.

One thing it can do at first is not to place any buffers on the stack:
always allocated them in the heap.  This might be a little less convenient,
since the heaps are susceptible to fragmentation, but will prevent against
the buffer overflows from modifying critical stack info like the return value,
thus making stack smashing harder.

Another thing is what if we created a separate stack for just the 
return addesses of called procedures?  We have a return address stack,
and a data stack in different places in memory.  Now no overflow from the
stack can affect the control flow of the program (well, not by overwriting
the return value at least).  Of course, two stacks makes the memory layout
scheme a little more weird, but we can handle that.  

A little more difficult to do:  at compile time determine which buffers
are taking input from the user, and are susceptible to overflow attacks.
The compiler can do this for the easy cases by just looking to see if there
are bound checks on the buffer size and what we are writing in to it.  If
it sees there are none, then allocate the buffer in a different place
in memory, such as on a separate page.  Then the system will page fault
if there is an overflow.  We shouldn't do this for all buffers since
that would be too many pages.  

The compiler could also provide compile directives that allow the
programmer to say "this is an untrusted buffer, put it somewhere
safe".  Then the compiler could place it on a separate page or do something
to make it more safe.

Another thing the compiler could try to do is automatically insert bounds
checking code before buffer references.  Of course, this is hard to do
since a lot of times the buffer is just referenced by a pointer, and 
the pointer does not have an indication what the size of the buffer is.
But, for cases when the size is known, we could do this.

Ok, now for the big scheme:  we can make C pointers safe.  We could
probably do this transparently to the programmer.  Here's how I do it:
a pointer of any data type actually consists of two pointers:  one to
the beginning of the memory chuck it points to, and one to the end of
the memory chunk.  For instance, normally, we get a pointer back from
malloc.  This pointer just points to beginning of the memory space we got.
However, malloc knows where the end of the memory chunk, so why not have it
hide a pointer to that end in the pointer structure it returns?  A similar
thing can be done for arrays allocated automatically on the stack.

This is great.  The compiler can now check every memory reference to make
sure it is in bounds of the memory it was assigned to.  Thus, it can always
check to make sure the buffer isn't overflowing.

Plus, we can make pointer to pointer casting operations work still.
For instance, if we cast a (int *) to a (char *), our casting
operation just simply has to implicitly cast both the beginning
pointer and the ending pointer to make the system work.  (The (char *)'s
beginning pointer is the (int *)'s cast to be a char, and likewise,
the (char *)'s ending pointer is the (int *)'s cast to be a char).  

The only problem is that now weird pointer cast operations such as casting
an int to a pointer value will no longer work quite the same.  There is 
no way for us to know that this cast operation is safe, so we have to 
dissallow this. 

So, we can get safe pointer operations by augmenting the C pointers, and
by constraining the types of operations we allow on pointers.  Of course,
this might be too limiting, but it does give us 90% of the functionality
we normally use, with very little changes to how we use pointers.


- --------------------------------------------------------

Sorry about the length of this darn thing...  it seems to have gotten
away from me...

- --PAA03545.909791269/batman.CS.Berkeley.EDU--

------- End of Forwarded Message

@
