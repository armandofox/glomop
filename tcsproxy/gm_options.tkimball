!./configure --with-perlinc=/disks/barad-dur/now/pythia/release/lib/perl-5.002 --with-tcl=/usr/sww/tcl
!---------------------------------------------------------------------
!  BEGIN SITE-SPECIFIC CONFIGURATION
!
!  You MUST modify these parameters to create a working installation.
!  You can do this before or after running configure.
!----------------------------------------------------------------------

! Full path to the directory in which you found this file (top level of
!  the distribution)
!
proxy.home: /var/home/tkimball/tcsproxy


! Current Note:
! Location of LWP and MD5 Perl modules, if nonstandard.  Only needed
!   if you want to use the Perl-based HTML distiller (and/or write
!   additional Perl distillers)  *and* your LWP Perl module doesn't live
!   in a standard place.  See the README for more information.
!
! Suggested Note:
! Please locate the lib/perl-5.xxx directory that contain the LWP and
! MD5 Perl modules.

proxy.perlmod: /usr/opt1/perl-5.003/lib/site_perl

! Current:
!  magic URL names:  these should generally point to the Web server that
!  hosts TranSend's "support pages".
! 
! Suggested:
!  You will need to set up some type of website with some base information
!  for the service you are providing. This site will be used
!  primarily for helping the enduser configure their browser 
!  to use your proxy service, as well as configure user profile information
!  pretaining to the distillers.
frontend.webServerName: http://transend.CS.Berkeley.EDU
frontend.prefsFormDisplayUrl: http://transend.cs.berkeley.edu/prefs.html
frontend.prefsFormSubmitUrl: http://transend.cs.berkeley.edu/SetPrefs
frontend.getPrefsUrl: http://transend.cs.berkeley.edu/GetPrefs.html
frontend.prefsChangeUrlString: http://transend.cs.berkeley.edu/ChangePrefs
frontend.aggString: http://www.cs.berkeley.edu/agg/


! The address of the admin and urgent email for the frontend checker.
! The admin email address will be sent an email every time the frontend
! crashes, and is restartable. If the frontend can not be restarted,
! then urgent email is sent to both the admin and the 'urgent_email'
! account.
! 

frontend.admin_email: tkimball@cs.berkeley.edu
frontend.urgent_email: tkimball@cs.berkeley.edu
                                    
!
! RExec initialization params
! This functionalility will allow the proxy server to spawn workers 
! as needed when the load increases. The following set of configuration
! parameters specifies a pool of machines that can be used and the mechanism
! to be used to spawn processes to those machines.
!
! rexec.rsh: name of the remote shell program; (use /usr/bin/rsh along with a 
!            .rhosts file rather than /usr/kerberos/bin/rsh, unless you can 
!            arrange to have kerberos tickets on all the machines on which the
!            frontend and the PTM could possibly be running) 
!            Leave the rexec.rsh entry blank to disable remote execution
! rexec.args: arguments to be passed to the "rexec.rsh" program. *ALWAYS 
!             INCLUDE -n IF YOU ARE USING rsh *
! rexec.hosts: comma separated list of remote hosts. Each host can also be
!              assigned a priority. Higher priority hosts (i.e hosts with 
!              lower numbered priority) will be selected before lower priority 
!              hosts. The format is:
!                     hostname*priority,hostname*priority,....
!              If *priority is omitted, the priority defaults to zero.
!              e.g.: rexec.hosts: u31,u32,u33*1,u34*1,u35*2
!              (In the above example, the hosts u31 and u32 have priority zero)
!
! Example:
rexec.rsh: 
rexec.args: -n
!rexec.hosts: u42,u43,u44,u45,u46,u47,u48,u49,u50


!--------------------------------
! Cache subsystem configuration
!------------------------------
! A list of hosts running cache nodes; there must be at least 1.
! (port 3128 is assumed, since that's what Harvest uses)

! Machines with the Harvest Cache running
cache.Partition: transend1 transend2 transend3 transend4

!------------------------------------------------------------
!   END SITE SPECIFIC CONFIGURATION
!------------------------------------------------------------

! For cache queries, what is the UDP timeout and # retries?
cache.UDP_timeout_sec: 0
cache.UDP_timeout_usec: 99000
cache.UDP_retries: 3

!------------------------------
!   Distiller configuration
!
! The current distrubition ships with distillers for 
! on-the-fly image distilliation. 
!
! Each line in the distillers database has the following format:
! dist.<distiller-type>: <executable-path> <auto-launch-limit-ms> \
!			<averaging-interval-ms> <distiller args ...> \
!			-- <additional args>
!
! Currently the auto-launch-limit-ms param is the max tolerable queue 
! length. Set it to zero if you want to disable auto-launching.
!
! For both <auto-launch-limit-ms> and <averaging-interval-ms>, you can
! specify - or 0 to use the built-in default value.
!
! <distiller-args> (optional) can be any of the command line arguments that 
! the distiller can understand. Specifically you can use the -n argument to 
! set the notification timeout and -m to set the DistillerMain timeout.
!
! In most cases, you will not need to specify any arguments other than the
! executable path (and any possible additional arguments that the distiller
! might require)
!

dist.transend/text/html:  sbin/perl_stub -- perl_dir/transend.text.html
dist.transend/image/gif: sbin/giftojpg_munger
dist.transend/image/jpeg: sbin/jpg_munger

!------------------------------
!  PTM configuration
!------------------------------
! location of the PTM executable
!
ptm.executable: /var/home/tkimball/tcsproxy/new_dist/sbin/ptm

!
! PTM beaconing channel: <multicast-ip-addr>/<port>[/<ttl>]
!
! Choose a random multicast address that will (hopefully) not conflict
! with anyone elses!
! example:
! ptm.multicast: 224.100.101.11/7456/4
!


ptm.multicast: 224.100.101.15/9012/4

!
! The time interval in milliseconds between beacons from the PTM
! (You should not need to modify this)
!
ptm.beacon_ms: 1000

!
! The number of beacons that may be lost before the frontend assumes that
! the PTM has died. i.e. the frontend will try to restart the PTM if it does
! not hear any beacons for a time interval of ptm.lost_beacons * ptm.beacon_ms
! (You should not need to modify this)
!
ptm.lost_beacons: 3

!------------------------------ 
! Front end configuration
!------------------------------ 
! port to listen on
!
frontend.http_listen_port: 5001
frontend.wing_listen_port: 5002
!
! User prefs gdbm database
!
frontend.userprefs: uprefs.gdbm
!
! Number of worker threads
!
frontend.nthreads: 400
!
! Amount by which to boost priority of accept()'ing thread
!
frontend.acceptPrio: 30


!------------------------------
!  GUI Monitor configuration
!------------------------------
!
! Monitor listening channel: <ip-addr>/<port>[/<ttl>]
! <ip-addr> may be a multicast IP, a unicast IP, or a (unicast) hostname
! Note: This address *SHOULD* be different from the PTM multicast address
!
! Example: 
! Monitor.listen: 228.8.8.11/9977
Monitor.listen: 228.8.8.14/9019/4
!
!  Monitor X resources
!
!  The toplevel frame (containing the "Show" and "Kill" buttons and the
!  label displaying the unit's name) is called Top.
! *Top.show.background:
*Top.label.background: white
*Top.label.width: 25
*Top.host.background: white
*Top.host.width: 25
*Top.kill.foreground: red
*Top.rsh: rsh
!
! destroyondeath: yes => the toplevel window for the unit will be destroyed 
! when a death packet is received
!
*Top.destroyondeath: yes
!
! noicons: yes => hiding a toplevel will iconify it
!          no  => hiding a toplevel will withdraw it
!
*Top.noicons: yes

prefetch.href: 10
